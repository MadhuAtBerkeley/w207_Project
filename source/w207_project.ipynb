{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4dbced162440c393a0a5b7e5aee344711a30e994"
   },
   "source": [
    "# Facial Keypoint Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "369fa247a546e39d82bdfdc5b7d4ed58baa40e4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from keras import backend\n",
    "import os, gc, json, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del model # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))\n",
    "    \n",
    "reset_keras()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "fa1b76273d02502e3fd668dddf74ecf522044524"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../output/'):\n",
    "    os.makedirs('../output/model')\n",
    "    os.makedirs('../output/history')\n",
    "    \n",
    "    \n",
    "model_dir = \"../output/model/\"\n",
    "history_dir = \"../output/history/\"\n",
    "\n",
    "train_file = '../input/training/training.csv'\n",
    "test_file = '../input/test/test.csv'\n",
    "train_data = pd.read_csv(train_file)  \n",
    "test_data = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "cfd045f7166f9cce2e2075b3ead83813d07012c8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <td>66.0336</td>\n",
       "      <td>64.3329</td>\n",
       "      <td>65.0571</td>\n",
       "      <td>65.2257</td>\n",
       "      <td>66.7253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <td>39.0023</td>\n",
       "      <td>34.9701</td>\n",
       "      <td>34.9096</td>\n",
       "      <td>37.2618</td>\n",
       "      <td>39.6213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <td>30.227</td>\n",
       "      <td>29.9493</td>\n",
       "      <td>30.9038</td>\n",
       "      <td>32.0231</td>\n",
       "      <td>32.2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <td>36.4217</td>\n",
       "      <td>33.4487</td>\n",
       "      <td>34.9096</td>\n",
       "      <td>37.2618</td>\n",
       "      <td>38.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "      <td>59.5821</td>\n",
       "      <td>58.8562</td>\n",
       "      <td>59.412</td>\n",
       "      <td>60.0033</td>\n",
       "      <td>58.5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye_inner_corner_y</th>\n",
       "      <td>39.6474</td>\n",
       "      <td>35.2743</td>\n",
       "      <td>36.321</td>\n",
       "      <td>39.1272</td>\n",
       "      <td>39.6213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye_outer_corner_x</th>\n",
       "      <td>73.1303</td>\n",
       "      <td>70.7227</td>\n",
       "      <td>70.9844</td>\n",
       "      <td>72.3147</td>\n",
       "      <td>72.5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eye_outer_corner_y</th>\n",
       "      <td>39.97</td>\n",
       "      <td>36.1872</td>\n",
       "      <td>36.321</td>\n",
       "      <td>38.381</td>\n",
       "      <td>39.8845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_inner_corner_x</th>\n",
       "      <td>36.3566</td>\n",
       "      <td>36.0347</td>\n",
       "      <td>37.6781</td>\n",
       "      <td>37.6186</td>\n",
       "      <td>36.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_inner_corner_y</th>\n",
       "      <td>37.3894</td>\n",
       "      <td>34.3615</td>\n",
       "      <td>36.321</td>\n",
       "      <td>38.7541</td>\n",
       "      <td>39.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_outer_corner_x</th>\n",
       "      <td>23.4529</td>\n",
       "      <td>24.4725</td>\n",
       "      <td>24.9764</td>\n",
       "      <td>25.3073</td>\n",
       "      <td>22.5061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eye_outer_corner_y</th>\n",
       "      <td>37.3894</td>\n",
       "      <td>33.1444</td>\n",
       "      <td>36.6032</td>\n",
       "      <td>38.0079</td>\n",
       "      <td>38.3052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eyebrow_inner_end_x</th>\n",
       "      <td>56.9533</td>\n",
       "      <td>53.9874</td>\n",
       "      <td>55.7425</td>\n",
       "      <td>56.4338</td>\n",
       "      <td>57.2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eyebrow_inner_end_y</th>\n",
       "      <td>29.0336</td>\n",
       "      <td>28.2759</td>\n",
       "      <td>27.5709</td>\n",
       "      <td>30.9299</td>\n",
       "      <td>30.6722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eyebrow_outer_end_x</th>\n",
       "      <td>80.2271</td>\n",
       "      <td>78.6342</td>\n",
       "      <td>78.8874</td>\n",
       "      <td>77.9103</td>\n",
       "      <td>77.7629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_eyebrow_outer_end_y</th>\n",
       "      <td>32.2281</td>\n",
       "      <td>30.4059</td>\n",
       "      <td>32.6516</td>\n",
       "      <td>31.6657</td>\n",
       "      <td>31.7372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eyebrow_inner_end_x</th>\n",
       "      <td>40.2276</td>\n",
       "      <td>42.7289</td>\n",
       "      <td>42.1939</td>\n",
       "      <td>41.6715</td>\n",
       "      <td>38.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eyebrow_inner_end_y</th>\n",
       "      <td>29.0023</td>\n",
       "      <td>26.146</td>\n",
       "      <td>28.1355</td>\n",
       "      <td>31.05</td>\n",
       "      <td>30.9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eyebrow_outer_end_x</th>\n",
       "      <td>16.3564</td>\n",
       "      <td>16.8654</td>\n",
       "      <td>16.7912</td>\n",
       "      <td>20.458</td>\n",
       "      <td>15.9259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_eyebrow_outer_end_y</th>\n",
       "      <td>29.6475</td>\n",
       "      <td>27.0589</td>\n",
       "      <td>32.0871</td>\n",
       "      <td>29.9093</td>\n",
       "      <td>30.6722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nose_tip_x</th>\n",
       "      <td>44.4206</td>\n",
       "      <td>48.2063</td>\n",
       "      <td>47.5573</td>\n",
       "      <td>51.8851</td>\n",
       "      <td>43.2995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nose_tip_y</th>\n",
       "      <td>57.0668</td>\n",
       "      <td>55.6609</td>\n",
       "      <td>53.5389</td>\n",
       "      <td>54.1665</td>\n",
       "      <td>64.8895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_left_corner_x</th>\n",
       "      <td>61.1953</td>\n",
       "      <td>56.4214</td>\n",
       "      <td>60.8229</td>\n",
       "      <td>65.5989</td>\n",
       "      <td>60.6714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_left_corner_y</th>\n",
       "      <td>79.9702</td>\n",
       "      <td>76.352</td>\n",
       "      <td>73.0143</td>\n",
       "      <td>72.7037</td>\n",
       "      <td>77.5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_right_corner_x</th>\n",
       "      <td>28.6145</td>\n",
       "      <td>35.1224</td>\n",
       "      <td>33.7263</td>\n",
       "      <td>37.2455</td>\n",
       "      <td>31.1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_right_corner_y</th>\n",
       "      <td>77.389</td>\n",
       "      <td>76.0477</td>\n",
       "      <td>72.732</td>\n",
       "      <td>74.1955</td>\n",
       "      <td>76.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_center_top_lip_x</th>\n",
       "      <td>43.3126</td>\n",
       "      <td>46.6846</td>\n",
       "      <td>47.2749</td>\n",
       "      <td>50.3032</td>\n",
       "      <td>44.9627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_center_top_lip_y</th>\n",
       "      <td>72.9355</td>\n",
       "      <td>70.2666</td>\n",
       "      <td>70.1918</td>\n",
       "      <td>70.0917</td>\n",
       "      <td>73.7074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_center_bottom_lip_x</th>\n",
       "      <td>43.1307</td>\n",
       "      <td>45.4679</td>\n",
       "      <td>47.2749</td>\n",
       "      <td>51.5612</td>\n",
       "      <td>44.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_center_bottom_lip_y</th>\n",
       "      <td>84.4858</td>\n",
       "      <td>85.4802</td>\n",
       "      <td>78.6594</td>\n",
       "      <td>78.2684</td>\n",
       "      <td>86.8712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <td>238 236 237 238 240 240 239 241 241 243 240 23...</td>\n",
       "      <td>219 215 204 196 204 211 212 200 180 168 178 19...</td>\n",
       "      <td>144 142 159 180 188 188 184 180 167 132 84 59 ...</td>\n",
       "      <td>193 192 193 194 194 194 193 192 168 111 50 12 ...</td>\n",
       "      <td>147 148 160 196 215 214 216 217 219 220 206 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           0  \\\n",
       "left_eye_center_x                                                    66.0336   \n",
       "left_eye_center_y                                                    39.0023   \n",
       "right_eye_center_x                                                    30.227   \n",
       "right_eye_center_y                                                   36.4217   \n",
       "left_eye_inner_corner_x                                              59.5821   \n",
       "left_eye_inner_corner_y                                              39.6474   \n",
       "left_eye_outer_corner_x                                              73.1303   \n",
       "left_eye_outer_corner_y                                                39.97   \n",
       "right_eye_inner_corner_x                                             36.3566   \n",
       "right_eye_inner_corner_y                                             37.3894   \n",
       "right_eye_outer_corner_x                                             23.4529   \n",
       "right_eye_outer_corner_y                                             37.3894   \n",
       "left_eyebrow_inner_end_x                                             56.9533   \n",
       "left_eyebrow_inner_end_y                                             29.0336   \n",
       "left_eyebrow_outer_end_x                                             80.2271   \n",
       "left_eyebrow_outer_end_y                                             32.2281   \n",
       "right_eyebrow_inner_end_x                                            40.2276   \n",
       "right_eyebrow_inner_end_y                                            29.0023   \n",
       "right_eyebrow_outer_end_x                                            16.3564   \n",
       "right_eyebrow_outer_end_y                                            29.6475   \n",
       "nose_tip_x                                                           44.4206   \n",
       "nose_tip_y                                                           57.0668   \n",
       "mouth_left_corner_x                                                  61.1953   \n",
       "mouth_left_corner_y                                                  79.9702   \n",
       "mouth_right_corner_x                                                 28.6145   \n",
       "mouth_right_corner_y                                                  77.389   \n",
       "mouth_center_top_lip_x                                               43.3126   \n",
       "mouth_center_top_lip_y                                               72.9355   \n",
       "mouth_center_bottom_lip_x                                            43.1307   \n",
       "mouth_center_bottom_lip_y                                            84.4858   \n",
       "Image                      238 236 237 238 240 240 239 241 241 243 240 23...   \n",
       "\n",
       "                                                                           1  \\\n",
       "left_eye_center_x                                                    64.3329   \n",
       "left_eye_center_y                                                    34.9701   \n",
       "right_eye_center_x                                                   29.9493   \n",
       "right_eye_center_y                                                   33.4487   \n",
       "left_eye_inner_corner_x                                              58.8562   \n",
       "left_eye_inner_corner_y                                              35.2743   \n",
       "left_eye_outer_corner_x                                              70.7227   \n",
       "left_eye_outer_corner_y                                              36.1872   \n",
       "right_eye_inner_corner_x                                             36.0347   \n",
       "right_eye_inner_corner_y                                             34.3615   \n",
       "right_eye_outer_corner_x                                             24.4725   \n",
       "right_eye_outer_corner_y                                             33.1444   \n",
       "left_eyebrow_inner_end_x                                             53.9874   \n",
       "left_eyebrow_inner_end_y                                             28.2759   \n",
       "left_eyebrow_outer_end_x                                             78.6342   \n",
       "left_eyebrow_outer_end_y                                             30.4059   \n",
       "right_eyebrow_inner_end_x                                            42.7289   \n",
       "right_eyebrow_inner_end_y                                             26.146   \n",
       "right_eyebrow_outer_end_x                                            16.8654   \n",
       "right_eyebrow_outer_end_y                                            27.0589   \n",
       "nose_tip_x                                                           48.2063   \n",
       "nose_tip_y                                                           55.6609   \n",
       "mouth_left_corner_x                                                  56.4214   \n",
       "mouth_left_corner_y                                                   76.352   \n",
       "mouth_right_corner_x                                                 35.1224   \n",
       "mouth_right_corner_y                                                 76.0477   \n",
       "mouth_center_top_lip_x                                               46.6846   \n",
       "mouth_center_top_lip_y                                               70.2666   \n",
       "mouth_center_bottom_lip_x                                            45.4679   \n",
       "mouth_center_bottom_lip_y                                            85.4802   \n",
       "Image                      219 215 204 196 204 211 212 200 180 168 178 19...   \n",
       "\n",
       "                                                                           2  \\\n",
       "left_eye_center_x                                                    65.0571   \n",
       "left_eye_center_y                                                    34.9096   \n",
       "right_eye_center_x                                                   30.9038   \n",
       "right_eye_center_y                                                   34.9096   \n",
       "left_eye_inner_corner_x                                               59.412   \n",
       "left_eye_inner_corner_y                                               36.321   \n",
       "left_eye_outer_corner_x                                              70.9844   \n",
       "left_eye_outer_corner_y                                               36.321   \n",
       "right_eye_inner_corner_x                                             37.6781   \n",
       "right_eye_inner_corner_y                                              36.321   \n",
       "right_eye_outer_corner_x                                             24.9764   \n",
       "right_eye_outer_corner_y                                             36.6032   \n",
       "left_eyebrow_inner_end_x                                             55.7425   \n",
       "left_eyebrow_inner_end_y                                             27.5709   \n",
       "left_eyebrow_outer_end_x                                             78.8874   \n",
       "left_eyebrow_outer_end_y                                             32.6516   \n",
       "right_eyebrow_inner_end_x                                            42.1939   \n",
       "right_eyebrow_inner_end_y                                            28.1355   \n",
       "right_eyebrow_outer_end_x                                            16.7912   \n",
       "right_eyebrow_outer_end_y                                            32.0871   \n",
       "nose_tip_x                                                           47.5573   \n",
       "nose_tip_y                                                           53.5389   \n",
       "mouth_left_corner_x                                                  60.8229   \n",
       "mouth_left_corner_y                                                  73.0143   \n",
       "mouth_right_corner_x                                                 33.7263   \n",
       "mouth_right_corner_y                                                  72.732   \n",
       "mouth_center_top_lip_x                                               47.2749   \n",
       "mouth_center_top_lip_y                                               70.1918   \n",
       "mouth_center_bottom_lip_x                                            47.2749   \n",
       "mouth_center_bottom_lip_y                                            78.6594   \n",
       "Image                      144 142 159 180 188 188 184 180 167 132 84 59 ...   \n",
       "\n",
       "                                                                           3  \\\n",
       "left_eye_center_x                                                    65.2257   \n",
       "left_eye_center_y                                                    37.2618   \n",
       "right_eye_center_x                                                   32.0231   \n",
       "right_eye_center_y                                                   37.2618   \n",
       "left_eye_inner_corner_x                                              60.0033   \n",
       "left_eye_inner_corner_y                                              39.1272   \n",
       "left_eye_outer_corner_x                                              72.3147   \n",
       "left_eye_outer_corner_y                                               38.381   \n",
       "right_eye_inner_corner_x                                             37.6186   \n",
       "right_eye_inner_corner_y                                             38.7541   \n",
       "right_eye_outer_corner_x                                             25.3073   \n",
       "right_eye_outer_corner_y                                             38.0079   \n",
       "left_eyebrow_inner_end_x                                             56.4338   \n",
       "left_eyebrow_inner_end_y                                             30.9299   \n",
       "left_eyebrow_outer_end_x                                             77.9103   \n",
       "left_eyebrow_outer_end_y                                             31.6657   \n",
       "right_eyebrow_inner_end_x                                            41.6715   \n",
       "right_eyebrow_inner_end_y                                              31.05   \n",
       "right_eyebrow_outer_end_x                                             20.458   \n",
       "right_eyebrow_outer_end_y                                            29.9093   \n",
       "nose_tip_x                                                           51.8851   \n",
       "nose_tip_y                                                           54.1665   \n",
       "mouth_left_corner_x                                                  65.5989   \n",
       "mouth_left_corner_y                                                  72.7037   \n",
       "mouth_right_corner_x                                                 37.2455   \n",
       "mouth_right_corner_y                                                 74.1955   \n",
       "mouth_center_top_lip_x                                               50.3032   \n",
       "mouth_center_top_lip_y                                               70.0917   \n",
       "mouth_center_bottom_lip_x                                            51.5612   \n",
       "mouth_center_bottom_lip_y                                            78.2684   \n",
       "Image                      193 192 193 194 194 194 193 192 168 111 50 12 ...   \n",
       "\n",
       "                                                                           4  \n",
       "left_eye_center_x                                                    66.7253  \n",
       "left_eye_center_y                                                    39.6213  \n",
       "right_eye_center_x                                                   32.2448  \n",
       "right_eye_center_y                                                    38.042  \n",
       "left_eye_inner_corner_x                                              58.5659  \n",
       "left_eye_inner_corner_y                                              39.6213  \n",
       "left_eye_outer_corner_x                                              72.5159  \n",
       "left_eye_outer_corner_y                                              39.8845  \n",
       "right_eye_inner_corner_x                                             36.9824  \n",
       "right_eye_inner_corner_y                                             39.0949  \n",
       "right_eye_outer_corner_x                                             22.5061  \n",
       "right_eye_outer_corner_y                                             38.3052  \n",
       "left_eyebrow_inner_end_x                                             57.2496  \n",
       "left_eyebrow_inner_end_y                                             30.6722  \n",
       "left_eyebrow_outer_end_x                                             77.7629  \n",
       "left_eyebrow_outer_end_y                                             31.7372  \n",
       "right_eyebrow_inner_end_x                                            38.0354  \n",
       "right_eyebrow_inner_end_y                                            30.9354  \n",
       "right_eyebrow_outer_end_x                                            15.9259  \n",
       "right_eyebrow_outer_end_y                                            30.6722  \n",
       "nose_tip_x                                                           43.2995  \n",
       "nose_tip_y                                                           64.8895  \n",
       "mouth_left_corner_x                                                  60.6714  \n",
       "mouth_left_corner_y                                                  77.5232  \n",
       "mouth_right_corner_x                                                 31.1918  \n",
       "mouth_right_corner_y                                                 76.9973  \n",
       "mouth_center_top_lip_x                                               44.9627  \n",
       "mouth_center_top_lip_y                                               73.7074  \n",
       "mouth_center_bottom_lip_x                                            44.2271  \n",
       "mouth_center_bottom_lip_y                                            86.8712  \n",
       "Image                      147 148 160 196 215 214 216 217 219 220 206 18...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14ae8eb84c1ed40db949d6dddeba331b2ed84487"
   },
   "source": [
    "Check missing values and replace NaN's with mean values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "67368f645afe618d6fc717552a6847de7e5ec66a"
   },
   "outputs": [],
   "source": [
    "train_data.isnull().any().value_counts()\n",
    "columns_nan = train_data.columns[train_data.isna().any()].tolist()\n",
    "train_data[columns_nan] = train_data[columns_nan].fillna(value=train_data[columns_nan].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1b88f1528838c0a8fec61f9a02a70b5077312e9"
   },
   "source": [
    "Create training vector with images and normalize thee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e78ca4523425835f1b584f3e30e5c9dcc8014253"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    image = train_data['Image'][i].split(' ')\n",
    "    image = ['0' if x == '' else x for x in image]\n",
    "    x_train.append(image)\n",
    "    \n",
    "x_train = np.array(x_train,dtype = 'float')\n",
    "x_train = x_train/255.0\n",
    "x_train = x_train.reshape(-1,96,96,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58a352bb3b38dadf37da1a6b62798fe1e3df8614"
   },
   "source": [
    "Display test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3e953b9fa753d6f7c1092a2d8d2faf6cff5a4f93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2].reshape(96,96),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a833f4cc5e559774d3a310fd09d40d31e49e71da"
   },
   "source": [
    "Generate labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "e9d804a035809cdf8ffda19f41ce3feb278a38fb"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_train = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    label = train_data.iloc[i,0:30]\n",
    "    y_train.append(label)\n",
    "    \n",
    "y_train = np.array(y_train,dtype = 'float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback function if detailed log required\n",
    "class History(tensorflow.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_loss = []\n",
    "        self.train_rmse = []\n",
    "        self.val_rmse = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.train_rmse.append(logs.get('rmse'))\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):    \n",
    "        self.val_rmse.append(logs.get('val_rmse'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        \n",
    "# Implement ModelCheckPoint callback function to save CNN model\n",
    "class CNN_ModelCheckpoint(tensorflow.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model, filename):\n",
    "        self.filename = filename\n",
    "        self.cnn_model = model\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.max_val_rmse = math.inf\n",
    "        \n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):    \n",
    "        val_rmse = logs.get('val_rmse')\n",
    "        if(val_rmse < self.max_val_rmse):\n",
    "           self.max_val_rmse = val_rmse\n",
    "           self.cnn_model.save(self.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 96, 96, 32)        288       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 64)        18432     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 96)        55296     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 24, 24, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 24, 24, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       110592    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 256)         294912    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 512)         1179648   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 4,038,718\n",
      "Trainable params: 4,036,542\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model_input = Input(shape=(96,96,1))\n",
    "\n",
    "    x = Convolution2D(32, (3,3), padding='same', use_bias=False)(model_input)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(64, (3,3), padding='same', use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(96, (3,3), padding='same', use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(128, (3,3),padding='same', use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(256, (3,3),padding='same',use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Convolution2D(512, (3,3), padding='same', use_bias=False)(x)\n",
    "    x = LeakyReLU(alpha = 0.1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    model_output = Dense(30)(x)\n",
    "    model = Model(model_input, model_output, name=\"base_model\")\n",
    "    return model\n",
    "\n",
    "model = base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Custom RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "#from tensorflow.keras.optimizers.schedules import InverseTimeDecay\n",
    "\n",
    "# Use Nadam optimizer with variable learning rate\n",
    "optimizer = Nadam(lr=0.00001,\n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999,\n",
    "                  epsilon=1e-08,\n",
    "                  schedule_decay=0.004)\n",
    "\n",
    "\n",
    "# Loss: MSE and Metric = RMSE\n",
    "model.compile(optimizer= optimizer, \n",
    "              loss='mean_squared_error',\n",
    "              metrics=[rmse])\n",
    "\n",
    "#Callback to save the best model\n",
    "saveBase_Model = CNN_ModelCheckpoint(model, model_dir+\"base_model.h5\")\n",
    "\n",
    "#define callback functions\n",
    "callbacks = [#EarlyStopping(monitor='val_rmse', patience=3, verbose=2),\n",
    "             saveBase_Model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e4cf4686b410841f2e34dbb081f3429d1b0f67e9"
   },
   "source": [
    "Run for 1000 epochs and keeping 20% train-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "894af9cbfcf2dca50e7407946cad318157b77d0a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5639 samples, validate on 1410 samples\n",
      "WARNING:tensorflow:From /home/user1/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "5639/5639 [==============================] - 9s 2ms/sample - loss: 2561.7874 - rmse: 50.5991 - val_loss: 2639.2998 - val_rmse: 51.3701\n",
      "Epoch 2/1000\n",
      "5639/5639 [==============================] - 3s 578us/sample - loss: 2343.3655 - rmse: 48.3862 - val_loss: 2641.0817 - val_rmse: 51.3874\n",
      "Epoch 3/1000\n",
      "5639/5639 [==============================] - 3s 609us/sample - loss: 2052.1429 - rmse: 45.2590 - val_loss: 2643.1272 - val_rmse: 51.4073\n",
      "Epoch 4/1000\n",
      "5639/5639 [==============================] - 3s 588us/sample - loss: 1718.9655 - rmse: 41.3909 - val_loss: 2640.0194 - val_rmse: 51.3771\n",
      "Epoch 5/1000\n",
      "5639/5639 [==============================] - 4s 666us/sample - loss: 1399.8333 - rmse: 37.3175 - val_loss: 2627.1129 - val_rmse: 51.2513\n",
      "Epoch 6/1000\n",
      "5639/5639 [==============================] - 4s 672us/sample - loss: 1114.5163 - rmse: 33.2527 - val_loss: 2595.4941 - val_rmse: 50.9419\n",
      "Epoch 7/1000\n",
      "5639/5639 [==============================] - 4s 685us/sample - loss: 869.4478 - rmse: 29.3237 - val_loss: 2541.7121 - val_rmse: 50.4113\n",
      "Epoch 8/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 665.8348 - rmse: 25.6086 - val_loss: 2461.9355 - val_rmse: 49.6136\n",
      "Epoch 9/1000\n",
      "5639/5639 [==============================] - 3s 615us/sample - loss: 500.0177 - rmse: 22.1340 - val_loss: 2352.3175 - val_rmse: 48.4959\n",
      "Epoch 10/1000\n",
      "5639/5639 [==============================] - 4s 640us/sample - loss: 368.5840 - rmse: 18.9437 - val_loss: 2224.9817 - val_rmse: 47.1638\n",
      "Epoch 11/1000\n",
      "5639/5639 [==============================] - 3s 617us/sample - loss: 268.8271 - rmse: 16.1124 - val_loss: 2085.4330 - val_rmse: 45.6587\n",
      "Epoch 12/1000\n",
      "5639/5639 [==============================] - 3s 605us/sample - loss: 194.8431 - rmse: 13.6578 - val_loss: 1951.0717 - val_rmse: 44.1599\n",
      "Epoch 13/1000\n",
      "5639/5639 [==============================] - 3s 605us/sample - loss: 142.0808 - rmse: 11.6039 - val_loss: 1792.5737 - val_rmse: 42.3227\n",
      "Epoch 14/1000\n",
      "5639/5639 [==============================] - 4s 634us/sample - loss: 105.2760 - rmse: 9.9569 - val_loss: 1643.4402 - val_rmse: 40.5164\n",
      "Epoch 15/1000\n",
      "5639/5639 [==============================] - 3s 609us/sample - loss: 81.8119 - rmse: 8.7522 - val_loss: 1489.9690 - val_rmse: 38.5689\n",
      "Epoch 16/1000\n",
      "5639/5639 [==============================] - 4s 624us/sample - loss: 65.8256 - rmse: 7.8436 - val_loss: 1311.5190 - val_rmse: 36.1740\n",
      "Epoch 17/1000\n",
      "5639/5639 [==============================] - 4s 636us/sample - loss: 55.4007 - rmse: 7.2088 - val_loss: 1175.0993 - val_rmse: 34.2277\n",
      "Epoch 18/1000\n",
      "5639/5639 [==============================] - 3s 608us/sample - loss: 49.9311 - rmse: 6.8526 - val_loss: 1000.0490 - val_rmse: 31.5605\n",
      "Epoch 19/1000\n",
      "5639/5639 [==============================] - 3s 609us/sample - loss: 46.1507 - rmse: 6.5999 - val_loss: 880.8967 - val_rmse: 29.6045\n",
      "Epoch 20/1000\n",
      "5639/5639 [==============================] - 3s 608us/sample - loss: 44.0989 - rmse: 6.4637 - val_loss: 743.0978 - val_rmse: 27.1766\n",
      "Epoch 21/1000\n",
      "5639/5639 [==============================] - 3s 608us/sample - loss: 42.8127 - rmse: 6.3732 - val_loss: 635.7321 - val_rmse: 25.1213\n",
      "Epoch 22/1000\n",
      "5639/5639 [==============================] - 4s 651us/sample - loss: 41.7612 - rmse: 6.3003 - val_loss: 506.7411 - val_rmse: 22.4102\n",
      "Epoch 23/1000\n",
      "5639/5639 [==============================] - 4s 636us/sample - loss: 41.0430 - rmse: 6.2449 - val_loss: 435.9164 - val_rmse: 20.7724\n",
      "Epoch 24/1000\n",
      "5639/5639 [==============================] - 4s 637us/sample - loss: 40.5752 - rmse: 6.2117 - val_loss: 349.1777 - val_rmse: 18.5705\n",
      "Epoch 25/1000\n",
      "5639/5639 [==============================] - 3s 608us/sample - loss: 39.8280 - rmse: 6.1591 - val_loss: 269.2481 - val_rmse: 16.2765\n",
      "Epoch 26/1000\n",
      "5639/5639 [==============================] - 3s 610us/sample - loss: 39.6464 - rmse: 6.1443 - val_loss: 225.5761 - val_rmse: 14.8845\n",
      "Epoch 27/1000\n",
      "5639/5639 [==============================] - 4s 639us/sample - loss: 39.1904 - rmse: 6.1136 - val_loss: 191.2520 - val_rmse: 13.6742\n",
      "Epoch 28/1000\n",
      "5639/5639 [==============================] - 3s 609us/sample - loss: 38.9442 - rmse: 6.0950 - val_loss: 137.5897 - val_rmse: 11.5664\n",
      "Epoch 29/1000\n",
      "5639/5639 [==============================] - 4s 629us/sample - loss: 38.6681 - rmse: 6.0686 - val_loss: 88.9533 - val_rmse: 9.2060\n",
      "Epoch 30/1000\n",
      "5639/5639 [==============================] - 4s 640us/sample - loss: 38.4423 - rmse: 6.0558 - val_loss: 84.7266 - val_rmse: 9.0033\n",
      "Epoch 31/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 37.6833 - rmse: 5.9976 - val_loss: 63.8875 - val_rmse: 7.7709\n",
      "Epoch 32/1000\n",
      "5639/5639 [==============================] - 3s 615us/sample - loss: 37.7392 - rmse: 6.0015 - val_loss: 51.2031 - val_rmse: 6.9135\n",
      "Epoch 33/1000\n",
      "5639/5639 [==============================] - 4s 637us/sample - loss: 37.5862 - rmse: 5.9852 - val_loss: 45.9860 - val_rmse: 6.5179\n",
      "Epoch 34/1000\n",
      "5639/5639 [==============================] - 3s 612us/sample - loss: 37.3528 - rmse: 5.9674 - val_loss: 28.8599 - val_rmse: 5.0600\n",
      "Epoch 35/1000\n",
      "5639/5639 [==============================] - 3s 614us/sample - loss: 36.9144 - rmse: 5.9343 - val_loss: 22.0460 - val_rmse: 4.3581\n",
      "Epoch 36/1000\n",
      "5639/5639 [==============================] - 4s 628us/sample - loss: 36.6646 - rmse: 5.9097 - val_loss: 20.8011 - val_rmse: 4.2222\n",
      "Epoch 37/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 36.5052 - rmse: 5.9019 - val_loss: 15.0653 - val_rmse: 3.4945\n",
      "Epoch 38/1000\n",
      "5639/5639 [==============================] - 3s 588us/sample - loss: 36.5484 - rmse: 5.8997 - val_loss: 16.8959 - val_rmse: 3.7709\n",
      "Epoch 39/1000\n",
      "5639/5639 [==============================] - 3s 608us/sample - loss: 35.9678 - rmse: 5.8584 - val_loss: 12.2112 - val_rmse: 3.1331\n",
      "Epoch 40/1000\n",
      "5639/5639 [==============================] - 3s 586us/sample - loss: 35.9328 - rmse: 5.8573 - val_loss: 13.8795 - val_rmse: 3.3647\n",
      "Epoch 41/1000\n",
      "5639/5639 [==============================] - 4s 623us/sample - loss: 35.6281 - rmse: 5.8307 - val_loss: 11.8897 - val_rmse: 3.0832\n",
      "Epoch 42/1000\n",
      "5639/5639 [==============================] - 3s 585us/sample - loss: 35.6136 - rmse: 5.8239 - val_loss: 12.1875 - val_rmse: 3.1377\n",
      "Epoch 43/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 35.3105 - rmse: 5.8006 - val_loss: 9.1259 - val_rmse: 2.6506\n",
      "Epoch 44/1000\n",
      "5639/5639 [==============================] - 4s 654us/sample - loss: 34.9015 - rmse: 5.7639 - val_loss: 8.3462 - val_rmse: 2.5302\n",
      "Epoch 45/1000\n",
      "5639/5639 [==============================] - 3s 615us/sample - loss: 34.7446 - rmse: 5.7572 - val_loss: 7.9545 - val_rmse: 2.4484\n",
      "Epoch 46/1000\n",
      "5639/5639 [==============================] - 3s 588us/sample - loss: 34.4124 - rmse: 5.7337 - val_loss: 8.5260 - val_rmse: 2.5684\n",
      "Epoch 47/1000\n",
      "5639/5639 [==============================] - 3s 580us/sample - loss: 34.3856 - rmse: 5.7247 - val_loss: 8.6960 - val_rmse: 2.5909\n",
      "Epoch 48/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 34.5670 - rmse: 5.7382 - val_loss: 7.8010 - val_rmse: 2.4402\n",
      "Epoch 49/1000\n",
      "5639/5639 [==============================] - 4s 625us/sample - loss: 34.0488 - rmse: 5.6957 - val_loss: 7.5420 - val_rmse: 2.3909\n",
      "Epoch 50/1000\n",
      "5639/5639 [==============================] - 3s 586us/sample - loss: 34.0587 - rmse: 5.6948 - val_loss: 7.8587 - val_rmse: 2.4588\n",
      "Epoch 51/1000\n",
      "5639/5639 [==============================] - 3s 610us/sample - loss: 33.7033 - rmse: 5.6680 - val_loss: 7.4039 - val_rmse: 2.3716\n",
      "Epoch 52/1000\n",
      "5639/5639 [==============================] - 3s 586us/sample - loss: 33.4763 - rmse: 5.6464 - val_loss: 7.8469 - val_rmse: 2.4575\n",
      "Epoch 53/1000\n",
      "5639/5639 [==============================] - 3s 611us/sample - loss: 33.5368 - rmse: 5.6563 - val_loss: 7.0860 - val_rmse: 2.3162\n",
      "Epoch 54/1000\n",
      "5639/5639 [==============================] - 4s 628us/sample - loss: 33.1198 - rmse: 5.6226 - val_loss: 7.0059 - val_rmse: 2.3024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "5639/5639 [==============================] - 3s 546us/sample - loss: 33.0305 - rmse: 5.6084 - val_loss: 7.8274 - val_rmse: 2.4574\n",
      "Epoch 56/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 32.8056 - rmse: 5.5889 - val_loss: 7.4262 - val_rmse: 2.3942\n",
      "Epoch 57/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 32.8594 - rmse: 5.5975 - val_loss: 6.9819 - val_rmse: 2.3026\n",
      "Epoch 58/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 32.2573 - rmse: 5.5444 - val_loss: 8.5147 - val_rmse: 2.5819\n",
      "Epoch 59/1000\n",
      "5639/5639 [==============================] - 3s 568us/sample - loss: 32.0432 - rmse: 5.5290 - val_loss: 6.9453 - val_rmse: 2.2923\n",
      "Epoch 60/1000\n",
      "5639/5639 [==============================] - 3s 572us/sample - loss: 31.9215 - rmse: 5.5124 - val_loss: 6.8651 - val_rmse: 2.2857\n",
      "Epoch 61/1000\n",
      "5639/5639 [==============================] - 3s 597us/sample - loss: 31.9809 - rmse: 5.5161 - val_loss: 6.8767 - val_rmse: 2.2798\n",
      "Epoch 62/1000\n",
      "5639/5639 [==============================] - 3s 548us/sample - loss: 31.7204 - rmse: 5.4983 - val_loss: 7.0994 - val_rmse: 2.3263\n",
      "Epoch 63/1000\n",
      "5639/5639 [==============================] - 3s 548us/sample - loss: 31.6341 - rmse: 5.4910 - val_loss: 7.1157 - val_rmse: 2.3299\n",
      "Epoch 64/1000\n",
      "5639/5639 [==============================] - 3s 590us/sample - loss: 31.5869 - rmse: 5.4855 - val_loss: 6.6119 - val_rmse: 2.2333\n",
      "Epoch 65/1000\n",
      "5639/5639 [==============================] - 3s 551us/sample - loss: 31.3818 - rmse: 5.4567 - val_loss: 14.6363 - val_rmse: 3.4697\n",
      "Epoch 66/1000\n",
      "5639/5639 [==============================] - 3s 544us/sample - loss: 31.3764 - rmse: 5.4656 - val_loss: 6.7697 - val_rmse: 2.2727\n",
      "Epoch 67/1000\n",
      "5639/5639 [==============================] - 3s 547us/sample - loss: 31.0178 - rmse: 5.4324 - val_loss: 6.7695 - val_rmse: 2.2664\n",
      "Epoch 68/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 30.7251 - rmse: 5.4057 - val_loss: 6.6181 - val_rmse: 2.2369\n",
      "Epoch 69/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 30.5497 - rmse: 5.3889 - val_loss: 7.2722 - val_rmse: 2.3735\n",
      "Epoch 70/1000\n",
      "5639/5639 [==============================] - 3s 544us/sample - loss: 30.6807 - rmse: 5.4015 - val_loss: 6.7844 - val_rmse: 2.2722\n",
      "Epoch 71/1000\n",
      "5639/5639 [==============================] - 3s 569us/sample - loss: 30.2381 - rmse: 5.3622 - val_loss: 6.4588 - val_rmse: 2.2086\n",
      "Epoch 72/1000\n",
      "5639/5639 [==============================] - 3s 548us/sample - loss: 30.2153 - rmse: 5.3625 - val_loss: 6.5270 - val_rmse: 2.2224\n",
      "Epoch 73/1000\n",
      "5639/5639 [==============================] - 3s 570us/sample - loss: 30.3410 - rmse: 5.3729 - val_loss: 6.3244 - val_rmse: 2.1797\n",
      "Epoch 74/1000\n",
      "5639/5639 [==============================] - 3s 546us/sample - loss: 30.1628 - rmse: 5.3546 - val_loss: 6.6609 - val_rmse: 2.2524\n",
      "Epoch 75/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 29.7312 - rmse: 5.3153 - val_loss: 8.0774 - val_rmse: 2.5183\n",
      "Epoch 76/1000\n",
      "5639/5639 [==============================] - 3s 543us/sample - loss: 29.7094 - rmse: 5.3180 - val_loss: 7.1365 - val_rmse: 2.3544\n",
      "Epoch 77/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 29.5903 - rmse: 5.3041 - val_loss: 6.3678 - val_rmse: 2.1937\n",
      "Epoch 78/1000\n",
      "5639/5639 [==============================] - 3s 543us/sample - loss: 29.5595 - rmse: 5.2998 - val_loss: 8.1663 - val_rmse: 2.5466\n",
      "Epoch 79/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 29.3977 - rmse: 5.2822 - val_loss: 6.4987 - val_rmse: 2.2254\n",
      "Epoch 80/1000\n",
      "5639/5639 [==============================] - 3s 575us/sample - loss: 29.3205 - rmse: 5.2795 - val_loss: 6.1410 - val_rmse: 2.1505\n",
      "Epoch 81/1000\n",
      "5639/5639 [==============================] - 3s 547us/sample - loss: 29.1019 - rmse: 5.2600 - val_loss: 6.1704 - val_rmse: 2.1542\n",
      "Epoch 82/1000\n",
      "5639/5639 [==============================] - 3s 549us/sample - loss: 29.0813 - rmse: 5.2583 - val_loss: 6.3136 - val_rmse: 2.1876\n",
      "Epoch 83/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 28.6642 - rmse: 5.2204 - val_loss: 6.6734 - val_rmse: 2.2583\n",
      "Epoch 84/1000\n",
      "5639/5639 [==============================] - 3s 543us/sample - loss: 29.0161 - rmse: 5.2497 - val_loss: 6.9020 - val_rmse: 2.3119\n",
      "Epoch 85/1000\n",
      "5639/5639 [==============================] - 3s 571us/sample - loss: 28.6360 - rmse: 5.2157 - val_loss: 6.0053 - val_rmse: 2.1250\n",
      "Epoch 86/1000\n",
      "5639/5639 [==============================] - 3s 547us/sample - loss: 28.4811 - rmse: 5.2033 - val_loss: 6.4940 - val_rmse: 2.2247\n",
      "Epoch 87/1000\n",
      "5639/5639 [==============================] - 3s 570us/sample - loss: 28.2783 - rmse: 5.1811 - val_loss: 5.9750 - val_rmse: 2.1135\n",
      "Epoch 88/1000\n",
      "5639/5639 [==============================] - 3s 547us/sample - loss: 28.1542 - rmse: 5.1716 - val_loss: 7.0788 - val_rmse: 2.3453\n",
      "Epoch 89/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 28.0980 - rmse: 5.1611 - val_loss: 5.9649 - val_rmse: 2.1191\n",
      "Epoch 90/1000\n",
      "5639/5639 [==============================] - 3s 543us/sample - loss: 28.0007 - rmse: 5.1542 - val_loss: 6.3059 - val_rmse: 2.1898\n",
      "Epoch 91/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 27.7963 - rmse: 5.1359 - val_loss: 6.0409 - val_rmse: 2.1320\n",
      "Epoch 92/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 27.8034 - rmse: 5.1370 - val_loss: 5.9505 - val_rmse: 2.1155\n",
      "Epoch 93/1000\n",
      "5639/5639 [==============================] - 3s 544us/sample - loss: 27.3839 - rmse: 5.0977 - val_loss: 6.0402 - val_rmse: 2.1320\n",
      "Epoch 94/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 27.3461 - rmse: 5.0966 - val_loss: 6.0505 - val_rmse: 2.1350\n",
      "Epoch 95/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 27.2540 - rmse: 5.0841 - val_loss: 6.0950 - val_rmse: 2.1534\n",
      "Epoch 96/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 27.2159 - rmse: 5.0787 - val_loss: 5.9545 - val_rmse: 2.1221\n",
      "Epoch 97/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 27.1070 - rmse: 5.0698 - val_loss: 6.4503 - val_rmse: 2.2272\n",
      "Epoch 98/1000\n",
      "5639/5639 [==============================] - 3s 540us/sample - loss: 27.0338 - rmse: 5.0637 - val_loss: 7.6607 - val_rmse: 2.4624\n",
      "Epoch 99/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 27.1072 - rmse: 5.0704 - val_loss: 6.2450 - val_rmse: 2.1851\n",
      "Epoch 100/1000\n",
      "5639/5639 [==============================] - 3s 540us/sample - loss: 26.8412 - rmse: 5.0435 - val_loss: 6.2796 - val_rmse: 2.1918\n",
      "Epoch 101/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 26.6013 - rmse: 5.0213 - val_loss: 5.9811 - val_rmse: 2.1310\n",
      "Epoch 102/1000\n",
      "5639/5639 [==============================] - 3s 540us/sample - loss: 26.4579 - rmse: 5.0077 - val_loss: 6.3686 - val_rmse: 2.2147\n",
      "Epoch 103/1000\n",
      "5639/5639 [==============================] - 3s 570us/sample - loss: 26.3877 - rmse: 4.9998 - val_loss: 5.8885 - val_rmse: 2.0997\n",
      "Epoch 104/1000\n",
      "5639/5639 [==============================] - 3s 547us/sample - loss: 26.3862 - rmse: 5.0031 - val_loss: 6.6134 - val_rmse: 2.2630\n",
      "Epoch 105/1000\n",
      "5639/5639 [==============================] - 3s 539us/sample - loss: 26.1840 - rmse: 4.9812 - val_loss: 6.3410 - val_rmse: 2.2062\n",
      "Epoch 106/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 26.1679 - rmse: 4.9796 - val_loss: 6.2530 - val_rmse: 2.1896\n",
      "Epoch 107/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 25.9434 - rmse: 4.9561 - val_loss: 6.1242 - val_rmse: 2.1653\n",
      "Epoch 108/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 25.8286 - rmse: 4.9472 - val_loss: 5.9352 - val_rmse: 2.1185\n",
      "Epoch 109/1000\n",
      "5639/5639 [==============================] - 3s 565us/sample - loss: 25.6148 - rmse: 4.9309 - val_loss: 6.5460 - val_rmse: 2.2547\n",
      "Epoch 110/1000\n",
      "5639/5639 [==============================] - 3s 600us/sample - loss: 25.5213 - rmse: 4.9163 - val_loss: 5.5729 - val_rmse: 2.0432\n",
      "Epoch 111/1000\n",
      "5639/5639 [==============================] - 3s 576us/sample - loss: 25.4775 - rmse: 4.9132 - val_loss: 6.0040 - val_rmse: 2.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "5639/5639 [==============================] - 3s 567us/sample - loss: 25.3650 - rmse: 4.9056 - val_loss: 5.8172 - val_rmse: 2.0988\n",
      "Epoch 113/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 25.2329 - rmse: 4.8915 - val_loss: 6.4229 - val_rmse: 2.2362\n",
      "Epoch 114/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 25.1260 - rmse: 4.8751 - val_loss: 5.7216 - val_rmse: 2.0803\n",
      "Epoch 115/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 24.8596 - rmse: 4.8542 - val_loss: 5.9939 - val_rmse: 2.1388\n",
      "Epoch 116/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 24.9050 - rmse: 4.8572 - val_loss: 5.7912 - val_rmse: 2.0982\n",
      "Epoch 117/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 24.8553 - rmse: 4.8497 - val_loss: 5.5755 - val_rmse: 2.0497\n",
      "Epoch 118/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 24.9591 - rmse: 4.8603 - val_loss: 5.5859 - val_rmse: 2.0493\n",
      "Epoch 119/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 24.5657 - rmse: 4.8180 - val_loss: 5.8621 - val_rmse: 2.1144\n",
      "Epoch 120/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 24.4453 - rmse: 4.8092 - val_loss: 6.1306 - val_rmse: 2.1699\n",
      "Epoch 121/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 24.2773 - rmse: 4.7921 - val_loss: 5.8751 - val_rmse: 2.1138\n",
      "Epoch 122/1000\n",
      "5639/5639 [==============================] - 3s 558us/sample - loss: 24.4685 - rmse: 4.8150 - val_loss: 5.5500 - val_rmse: 2.0390\n",
      "Epoch 123/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 24.0849 - rmse: 4.7734 - val_loss: 5.9654 - val_rmse: 2.1365\n",
      "Epoch 124/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 24.2144 - rmse: 4.7887 - val_loss: 5.7162 - val_rmse: 2.0711\n",
      "Epoch 125/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 24.1692 - rmse: 4.7796 - val_loss: 5.8897 - val_rmse: 2.1280\n",
      "Epoch 126/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 23.8922 - rmse: 4.7497 - val_loss: 5.9481 - val_rmse: 2.1354\n",
      "Epoch 127/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 23.8362 - rmse: 4.7485 - val_loss: 5.7111 - val_rmse: 2.0856\n",
      "Epoch 128/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 23.5668 - rmse: 4.7249 - val_loss: 5.7074 - val_rmse: 2.0869\n",
      "Epoch 129/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 23.5853 - rmse: 4.7249 - val_loss: 6.2098 - val_rmse: 2.1999\n",
      "Epoch 130/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 23.5027 - rmse: 4.7143 - val_loss: 7.2405 - val_rmse: 2.4007\n",
      "Epoch 131/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 23.3820 - rmse: 4.7044 - val_loss: 7.1090 - val_rmse: 2.3751\n",
      "Epoch 132/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 23.2140 - rmse: 4.6848 - val_loss: 5.4100 - val_rmse: 2.0142\n",
      "Epoch 133/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 23.0514 - rmse: 4.6676 - val_loss: 5.9447 - val_rmse: 2.1327\n",
      "Epoch 134/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 23.1663 - rmse: 4.6803 - val_loss: 5.3159 - val_rmse: 1.9862\n",
      "Epoch 135/1000\n",
      "5639/5639 [==============================] - 3s 580us/sample - loss: 23.0605 - rmse: 4.6679 - val_loss: 5.2954 - val_rmse: 1.9844\n",
      "Epoch 136/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 23.0703 - rmse: 4.6704 - val_loss: 7.4187 - val_rmse: 2.4382\n",
      "Epoch 137/1000\n",
      "5639/5639 [==============================] - 3s 582us/sample - loss: 22.8436 - rmse: 4.6467 - val_loss: 5.2571 - val_rmse: 1.9800\n",
      "Epoch 138/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 22.6517 - rmse: 4.6257 - val_loss: 5.5369 - val_rmse: 2.0383\n",
      "Epoch 139/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 22.4748 - rmse: 4.6050 - val_loss: 5.3588 - val_rmse: 2.0108\n",
      "Epoch 140/1000\n",
      "5639/5639 [==============================] - 3s 544us/sample - loss: 22.5336 - rmse: 4.6164 - val_loss: 5.2811 - val_rmse: 1.9900\n",
      "Epoch 141/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 22.3863 - rmse: 4.5998 - val_loss: 5.3654 - val_rmse: 2.0001\n",
      "Epoch 142/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 22.4156 - rmse: 4.6003 - val_loss: 6.2788 - val_rmse: 2.2207\n",
      "Epoch 143/1000\n",
      "5639/5639 [==============================] - 3s 560us/sample - loss: 22.2741 - rmse: 4.5836 - val_loss: 5.1311 - val_rmse: 1.9508\n",
      "Epoch 144/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 22.0378 - rmse: 4.5653 - val_loss: 5.5368 - val_rmse: 2.0384\n",
      "Epoch 145/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 22.0836 - rmse: 4.5632 - val_loss: 5.3680 - val_rmse: 2.0089\n",
      "Epoch 146/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 22.2017 - rmse: 4.5818 - val_loss: 5.6452 - val_rmse: 2.0741\n",
      "Epoch 147/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 21.9109 - rmse: 4.5489 - val_loss: 5.9077 - val_rmse: 2.1327\n",
      "Epoch 148/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 21.8163 - rmse: 4.5393 - val_loss: 5.4461 - val_rmse: 2.0257\n",
      "Epoch 149/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 21.6654 - rmse: 4.5260 - val_loss: 5.7000 - val_rmse: 2.0910\n",
      "Epoch 150/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 21.5719 - rmse: 4.5130 - val_loss: 6.3919 - val_rmse: 2.2374\n",
      "Epoch 151/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 21.4204 - rmse: 4.5047 - val_loss: 5.3321 - val_rmse: 2.0091\n",
      "Epoch 152/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 21.5367 - rmse: 4.5103 - val_loss: 5.6868 - val_rmse: 2.0879\n",
      "Epoch 153/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 21.3020 - rmse: 4.4840 - val_loss: 5.8918 - val_rmse: 2.1334\n",
      "Epoch 154/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 21.2075 - rmse: 4.4729 - val_loss: 5.6930 - val_rmse: 2.0816\n",
      "Epoch 155/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 21.2787 - rmse: 4.4806 - val_loss: 7.4859 - val_rmse: 2.4706\n",
      "Epoch 156/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 21.0922 - rmse: 4.4596 - val_loss: 7.7886 - val_rmse: 2.5201\n",
      "Epoch 157/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 21.0791 - rmse: 4.4587 - val_loss: 6.1265 - val_rmse: 2.1943\n",
      "Epoch 158/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 20.9343 - rmse: 4.4438 - val_loss: 5.9436 - val_rmse: 2.1511\n",
      "Epoch 159/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 20.7662 - rmse: 4.4236 - val_loss: 5.4289 - val_rmse: 2.0369\n",
      "Epoch 160/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 20.7819 - rmse: 4.4263 - val_loss: 6.0211 - val_rmse: 2.1712\n",
      "Epoch 161/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 20.6402 - rmse: 4.4113 - val_loss: 5.5192 - val_rmse: 2.0577\n",
      "Epoch 162/1000\n",
      "5639/5639 [==============================] - 3s 558us/sample - loss: 20.5382 - rmse: 4.3985 - val_loss: 4.9804 - val_rmse: 1.9348\n",
      "Epoch 163/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 20.5213 - rmse: 4.4036 - val_loss: 5.8314 - val_rmse: 2.1338\n",
      "Epoch 164/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 20.2655 - rmse: 4.3716 - val_loss: 5.1607 - val_rmse: 1.9771\n",
      "Epoch 165/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 20.3023 - rmse: 4.3760 - val_loss: 6.4154 - val_rmse: 2.2560\n",
      "Epoch 166/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 20.0530 - rmse: 4.3497 - val_loss: 4.8898 - val_rmse: 1.9141\n",
      "Epoch 167/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 20.0185 - rmse: 4.3472 - val_loss: 5.5928 - val_rmse: 2.0792\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5639/5639 [==============================] - 3s 529us/sample - loss: 20.0987 - rmse: 4.3568 - val_loss: 5.8545 - val_rmse: 2.1367\n",
      "Epoch 169/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 19.9523 - rmse: 4.3338 - val_loss: 5.3313 - val_rmse: 2.0192\n",
      "Epoch 170/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 19.9596 - rmse: 4.3403 - val_loss: 5.7155 - val_rmse: 2.1127\n",
      "Epoch 171/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 19.6260 - rmse: 4.3025 - val_loss: 5.2830 - val_rmse: 2.0084\n",
      "Epoch 172/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 19.6598 - rmse: 4.3085 - val_loss: 4.6336 - val_rmse: 1.8498\n",
      "Epoch 173/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 19.6136 - rmse: 4.2995 - val_loss: 4.7811 - val_rmse: 1.8850\n",
      "Epoch 174/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 19.4775 - rmse: 4.2897 - val_loss: 6.3065 - val_rmse: 2.2433\n",
      "Epoch 175/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 19.6092 - rmse: 4.2978 - val_loss: 4.7023 - val_rmse: 1.8690\n",
      "Epoch 176/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 19.4985 - rmse: 4.2895 - val_loss: 4.8270 - val_rmse: 1.9001\n",
      "Epoch 177/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 19.2559 - rmse: 4.2634 - val_loss: 4.9985 - val_rmse: 1.9448\n",
      "Epoch 178/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 19.2533 - rmse: 4.2632 - val_loss: 5.2338 - val_rmse: 2.0000\n",
      "Epoch 179/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 18.9802 - rmse: 4.2306 - val_loss: 5.1699 - val_rmse: 1.9877\n",
      "Epoch 180/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 18.8575 - rmse: 4.2181 - val_loss: 5.2735 - val_rmse: 2.0091\n",
      "Epoch 181/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 18.9669 - rmse: 4.2262 - val_loss: 5.5670 - val_rmse: 2.0809\n",
      "Epoch 182/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 18.7979 - rmse: 4.2124 - val_loss: 5.1043 - val_rmse: 1.9712\n",
      "Epoch 183/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 18.7389 - rmse: 4.2057 - val_loss: 4.8200 - val_rmse: 1.8993\n",
      "Epoch 184/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 18.7455 - rmse: 4.2025 - val_loss: 4.9790 - val_rmse: 1.9371\n",
      "Epoch 185/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 18.7869 - rmse: 4.2061 - val_loss: 4.8745 - val_rmse: 1.9172\n",
      "Epoch 186/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 18.4272 - rmse: 4.1684 - val_loss: 5.1004 - val_rmse: 1.9657\n",
      "Epoch 187/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 18.5299 - rmse: 4.1788 - val_loss: 5.3393 - val_rmse: 2.0334\n",
      "Epoch 188/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 18.4585 - rmse: 4.1719 - val_loss: 5.0363 - val_rmse: 1.9563\n",
      "Epoch 189/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 18.4286 - rmse: 4.1682 - val_loss: 5.1564 - val_rmse: 1.9847\n",
      "Epoch 190/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 18.2733 - rmse: 4.1521 - val_loss: 6.0592 - val_rmse: 2.1952\n",
      "Epoch 191/1000\n",
      "5639/5639 [==============================] - 3s 553us/sample - loss: 18.2778 - rmse: 4.1493 - val_loss: 4.4808 - val_rmse: 1.8220\n",
      "Epoch 192/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 18.1346 - rmse: 4.1370 - val_loss: 4.5874 - val_rmse: 1.8497\n",
      "Epoch 193/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 18.1013 - rmse: 4.1293 - val_loss: 6.1344 - val_rmse: 2.2117\n",
      "Epoch 194/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 17.9873 - rmse: 4.1125 - val_loss: 5.1268 - val_rmse: 1.9771\n",
      "Epoch 195/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 17.9050 - rmse: 4.1064 - val_loss: 5.1038 - val_rmse: 1.9790\n",
      "Epoch 196/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 18.1000 - rmse: 4.1266 - val_loss: 6.1623 - val_rmse: 2.2111\n",
      "Epoch 197/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 17.9331 - rmse: 4.1129 - val_loss: 5.9017 - val_rmse: 2.1670\n",
      "Epoch 198/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.7321 - rmse: 4.0858 - val_loss: 7.2036 - val_rmse: 2.4379\n",
      "Epoch 199/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 17.6038 - rmse: 4.0713 - val_loss: 5.3691 - val_rmse: 2.0422\n",
      "Epoch 200/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.5919 - rmse: 4.0682 - val_loss: 4.9799 - val_rmse: 1.9455\n",
      "Epoch 201/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.5124 - rmse: 4.0643 - val_loss: 5.0832 - val_rmse: 1.9761\n",
      "Epoch 202/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.4091 - rmse: 4.0515 - val_loss: 5.5875 - val_rmse: 2.0938\n",
      "Epoch 203/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 17.2732 - rmse: 4.0347 - val_loss: 4.8488 - val_rmse: 1.9220\n",
      "Epoch 204/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.2555 - rmse: 4.0335 - val_loss: 5.0365 - val_rmse: 1.9666\n",
      "Epoch 205/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.1222 - rmse: 4.0164 - val_loss: 4.6539 - val_rmse: 1.8691\n",
      "Epoch 206/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.0028 - rmse: 4.0026 - val_loss: 4.7810 - val_rmse: 1.9013\n",
      "Epoch 207/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 17.0591 - rmse: 4.0078 - val_loss: 5.0289 - val_rmse: 1.9529\n",
      "Epoch 208/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 16.9275 - rmse: 3.9971 - val_loss: 4.4741 - val_rmse: 1.8219\n",
      "Epoch 209/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 16.8707 - rmse: 3.9870 - val_loss: 5.0667 - val_rmse: 1.9691\n",
      "Epoch 210/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 16.9024 - rmse: 3.9906 - val_loss: 4.5994 - val_rmse: 1.8619\n",
      "Epoch 211/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 16.8499 - rmse: 3.9805 - val_loss: 5.7094 - val_rmse: 2.1305\n",
      "Epoch 212/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 16.6591 - rmse: 3.9609 - val_loss: 5.5893 - val_rmse: 2.0992\n",
      "Epoch 213/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 16.6219 - rmse: 3.9546 - val_loss: 4.4645 - val_rmse: 1.8253\n",
      "Epoch 214/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 16.7012 - rmse: 3.9678 - val_loss: 6.1773 - val_rmse: 2.2322\n",
      "Epoch 215/1000\n",
      "5639/5639 [==============================] - 3s 573us/sample - loss: 16.4209 - rmse: 3.9311 - val_loss: 4.4405 - val_rmse: 1.8186\n",
      "Epoch 216/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 16.4494 - rmse: 3.9339 - val_loss: 5.4220 - val_rmse: 2.0634\n",
      "Epoch 217/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 16.3457 - rmse: 3.9219 - val_loss: 5.2503 - val_rmse: 2.0197\n",
      "Epoch 218/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 16.2719 - rmse: 3.9100 - val_loss: 4.3385 - val_rmse: 1.7944\n",
      "Epoch 219/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 16.1841 - rmse: 3.9061 - val_loss: 4.7091 - val_rmse: 1.8925\n",
      "Epoch 220/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 16.1910 - rmse: 3.9016 - val_loss: 4.5713 - val_rmse: 1.8559\n",
      "Epoch 221/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 16.1404 - rmse: 3.8970 - val_loss: 4.4686 - val_rmse: 1.8286\n",
      "Epoch 222/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 16.1362 - rmse: 3.8981 - val_loss: 5.7156 - val_rmse: 2.1270\n",
      "Epoch 223/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 16.0205 - rmse: 3.8829 - val_loss: 4.6161 - val_rmse: 1.8671\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5639/5639 [==============================] - 3s 526us/sample - loss: 15.8697 - rmse: 3.8653 - val_loss: 4.5473 - val_rmse: 1.8523\n",
      "Epoch 225/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 15.8263 - rmse: 3.8578 - val_loss: 4.7241 - val_rmse: 1.8888\n",
      "Epoch 226/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 15.8898 - rmse: 3.8684 - val_loss: 4.4804 - val_rmse: 1.8352\n",
      "Epoch 227/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 15.7461 - rmse: 3.8480 - val_loss: 5.0554 - val_rmse: 1.9797\n",
      "Epoch 228/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 15.6372 - rmse: 3.8373 - val_loss: 5.9148 - val_rmse: 2.1790\n",
      "Epoch 229/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 15.5063 - rmse: 3.8193 - val_loss: 4.6518 - val_rmse: 1.8820\n",
      "Epoch 230/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 15.4810 - rmse: 3.8169 - val_loss: 5.4202 - val_rmse: 2.0717\n",
      "Epoch 231/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 15.6855 - rmse: 3.8401 - val_loss: 5.2438 - val_rmse: 2.0244\n",
      "Epoch 232/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 15.4494 - rmse: 3.8099 - val_loss: 4.8920 - val_rmse: 1.9371\n",
      "Epoch 233/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 15.3410 - rmse: 3.7949 - val_loss: 4.5510 - val_rmse: 1.8505\n",
      "Epoch 234/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 15.3198 - rmse: 3.7946 - val_loss: 4.7985 - val_rmse: 1.9171\n",
      "Epoch 235/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 15.2804 - rmse: 3.7908 - val_loss: 5.0641 - val_rmse: 1.9797\n",
      "Epoch 236/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 15.2262 - rmse: 3.7822 - val_loss: 4.5763 - val_rmse: 1.8600\n",
      "Epoch 237/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 15.0846 - rmse: 3.7706 - val_loss: 4.7343 - val_rmse: 1.9028\n",
      "Epoch 238/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 15.0267 - rmse: 3.7588 - val_loss: 4.4813 - val_rmse: 1.8372\n",
      "Epoch 239/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 14.9035 - rmse: 3.7413 - val_loss: 5.6965 - val_rmse: 2.1255\n",
      "Epoch 240/1000\n",
      "5639/5639 [==============================] - 3s 553us/sample - loss: 14.8022 - rmse: 3.7275 - val_loss: 6.0933 - val_rmse: 2.2169\n",
      "Epoch 241/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 14.7999 - rmse: 3.7305 - val_loss: 4.5232 - val_rmse: 1.8482\n",
      "Epoch 242/1000\n",
      "5639/5639 [==============================] - 3s 561us/sample - loss: 14.7063 - rmse: 3.7221 - val_loss: 4.2993 - val_rmse: 1.7912\n",
      "Epoch 243/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 14.8560 - rmse: 3.7368 - val_loss: 4.7499 - val_rmse: 1.9047\n",
      "Epoch 244/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 14.6633 - rmse: 3.7137 - val_loss: 4.2018 - val_rmse: 1.7655\n",
      "Epoch 245/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 14.7776 - rmse: 3.7306 - val_loss: 4.3160 - val_rmse: 1.7906\n",
      "Epoch 246/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 14.6399 - rmse: 3.7101 - val_loss: 4.4666 - val_rmse: 1.8306\n",
      "Epoch 247/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 14.6862 - rmse: 3.7159 - val_loss: 4.3816 - val_rmse: 1.8100\n",
      "Epoch 248/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 14.6193 - rmse: 3.7067 - val_loss: 5.4150 - val_rmse: 2.0701\n",
      "Epoch 249/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 14.4038 - rmse: 3.6744 - val_loss: 5.0429 - val_rmse: 1.9661\n",
      "Epoch 250/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 14.3571 - rmse: 3.6779 - val_loss: 4.4139 - val_rmse: 1.8213\n",
      "Epoch 251/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 14.4418 - rmse: 3.6865 - val_loss: 4.3800 - val_rmse: 1.8143\n",
      "Epoch 252/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 14.2750 - rmse: 3.6662 - val_loss: 6.9530 - val_rmse: 2.4103\n",
      "Epoch 253/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 14.2674 - rmse: 3.6610 - val_loss: 4.2783 - val_rmse: 1.7857\n",
      "Epoch 254/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 14.1644 - rmse: 3.6484 - val_loss: 5.3487 - val_rmse: 2.0521\n",
      "Epoch 255/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 14.1645 - rmse: 3.6444 - val_loss: 5.3719 - val_rmse: 2.0561\n",
      "Epoch 256/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 14.1014 - rmse: 3.6397 - val_loss: 4.4093 - val_rmse: 1.8227\n",
      "Epoch 257/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 14.0401 - rmse: 3.6372 - val_loss: 4.1692 - val_rmse: 1.7603\n",
      "Epoch 258/1000\n",
      "5639/5639 [==============================] - 3s 572us/sample - loss: 14.0435 - rmse: 3.6331 - val_loss: 4.1570 - val_rmse: 1.7575\n",
      "Epoch 259/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 13.8916 - rmse: 3.6132 - val_loss: 4.3282 - val_rmse: 1.8015\n",
      "Epoch 260/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 13.8406 - rmse: 3.6070 - val_loss: 6.3377 - val_rmse: 2.2817\n",
      "Epoch 261/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 13.7816 - rmse: 3.5951 - val_loss: 4.5114 - val_rmse: 1.8513\n",
      "Epoch 262/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 13.7524 - rmse: 3.5970 - val_loss: 4.2223 - val_rmse: 1.7789\n",
      "Epoch 263/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 13.7661 - rmse: 3.5964 - val_loss: 5.3527 - val_rmse: 2.0578\n",
      "Epoch 264/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.6023 - rmse: 3.5722 - val_loss: 5.5879 - val_rmse: 2.1197\n",
      "Epoch 265/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.6245 - rmse: 3.5777 - val_loss: 4.4500 - val_rmse: 1.8311\n",
      "Epoch 266/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 13.4278 - rmse: 3.5521 - val_loss: 6.0659 - val_rmse: 2.2216\n",
      "Epoch 267/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.4944 - rmse: 3.5605 - val_loss: 4.7468 - val_rmse: 1.9098\n",
      "Epoch 268/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 13.3487 - rmse: 3.5435 - val_loss: 5.3843 - val_rmse: 2.0618\n",
      "Epoch 269/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.4910 - rmse: 3.5575 - val_loss: 4.4206 - val_rmse: 1.8257\n",
      "Epoch 270/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 13.2694 - rmse: 3.5299 - val_loss: 5.3259 - val_rmse: 2.0536\n",
      "Epoch 271/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.3310 - rmse: 3.5394 - val_loss: 4.1899 - val_rmse: 1.7705\n",
      "Epoch 272/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.2706 - rmse: 3.5326 - val_loss: 4.8742 - val_rmse: 1.9477\n",
      "Epoch 273/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 13.2522 - rmse: 3.5275 - val_loss: 4.1430 - val_rmse: 1.7565\n",
      "Epoch 274/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 13.1554 - rmse: 3.5158 - val_loss: 4.7134 - val_rmse: 1.9096\n",
      "Epoch 275/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 13.0206 - rmse: 3.4974 - val_loss: 5.5821 - val_rmse: 2.1015\n",
      "Epoch 276/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 13.1055 - rmse: 3.5051 - val_loss: 5.0527 - val_rmse: 1.9889\n",
      "Epoch 277/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 13.0277 - rmse: 3.4961 - val_loss: 5.0863 - val_rmse: 1.9970\n",
      "Epoch 278/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.9629 - rmse: 3.4886 - val_loss: 4.4067 - val_rmse: 1.8237\n",
      "Epoch 279/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 12.9731 - rmse: 3.4907 - val_loss: 6.6459 - val_rmse: 2.3454\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5639/5639 [==============================] - 3s 528us/sample - loss: 12.9200 - rmse: 3.4817 - val_loss: 4.2043 - val_rmse: 1.7719\n",
      "Epoch 281/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 12.9022 - rmse: 3.4826 - val_loss: 5.0419 - val_rmse: 1.9781\n",
      "Epoch 282/1000\n",
      "5639/5639 [==============================] - 3s 569us/sample - loss: 12.8018 - rmse: 3.4685 - val_loss: 4.1116 - val_rmse: 1.7473\n",
      "Epoch 283/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 12.7294 - rmse: 3.4597 - val_loss: 4.6822 - val_rmse: 1.8935\n",
      "Epoch 284/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 12.6949 - rmse: 3.4503 - val_loss: 5.1719 - val_rmse: 2.0228\n",
      "Epoch 285/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 12.5367 - rmse: 3.4320 - val_loss: 4.2885 - val_rmse: 1.7957\n",
      "Epoch 286/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.6262 - rmse: 3.4414 - val_loss: 4.1879 - val_rmse: 1.7695\n",
      "Epoch 287/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 12.5261 - rmse: 3.4306 - val_loss: 4.0569 - val_rmse: 1.7360\n",
      "Epoch 288/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 12.5405 - rmse: 3.4303 - val_loss: 4.1098 - val_rmse: 1.7488\n",
      "Epoch 289/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 12.4557 - rmse: 3.4232 - val_loss: 4.3589 - val_rmse: 1.8162\n",
      "Epoch 290/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 12.3724 - rmse: 3.4080 - val_loss: 4.5517 - val_rmse: 1.8653\n",
      "Epoch 291/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.3645 - rmse: 3.4062 - val_loss: 4.1860 - val_rmse: 1.7712\n",
      "Epoch 292/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 12.2739 - rmse: 3.3969 - val_loss: 4.1060 - val_rmse: 1.7517\n",
      "Epoch 293/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.2681 - rmse: 3.3942 - val_loss: 4.3167 - val_rmse: 1.8065\n",
      "Epoch 294/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 12.0859 - rmse: 3.3671 - val_loss: 5.7124 - val_rmse: 2.1445\n",
      "Epoch 295/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 12.3097 - rmse: 3.3957 - val_loss: 4.3485 - val_rmse: 1.8193\n",
      "Epoch 296/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 12.1414 - rmse: 3.3724 - val_loss: 4.3894 - val_rmse: 1.8225\n",
      "Epoch 297/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.0461 - rmse: 3.3629 - val_loss: 4.3457 - val_rmse: 1.8174\n",
      "Epoch 298/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 12.0677 - rmse: 3.3663 - val_loss: 4.0756 - val_rmse: 1.7442\n",
      "Epoch 299/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 12.0141 - rmse: 3.3599 - val_loss: 4.0894 - val_rmse: 1.7480\n",
      "Epoch 300/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 11.9969 - rmse: 3.3579 - val_loss: 5.1097 - val_rmse: 2.0075\n",
      "Epoch 301/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 11.9210 - rmse: 3.3464 - val_loss: 5.0255 - val_rmse: 1.9850\n",
      "Epoch 302/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.8860 - rmse: 3.3375 - val_loss: 5.1411 - val_rmse: 2.0160\n",
      "Epoch 303/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.8193 - rmse: 3.3331 - val_loss: 5.6632 - val_rmse: 2.1309\n",
      "Epoch 304/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 11.8005 - rmse: 3.3257 - val_loss: 4.3255 - val_rmse: 1.8052\n",
      "Epoch 305/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 11.7123 - rmse: 3.3151 - val_loss: 5.9870 - val_rmse: 2.2111\n",
      "Epoch 306/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 11.8688 - rmse: 3.3350 - val_loss: 4.6977 - val_rmse: 1.9045\n",
      "Epoch 307/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 11.7325 - rmse: 3.3157 - val_loss: 4.5291 - val_rmse: 1.8678\n",
      "Epoch 308/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.5512 - rmse: 3.2928 - val_loss: 4.1126 - val_rmse: 1.7566\n",
      "Epoch 309/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 11.5729 - rmse: 3.2953 - val_loss: 4.0361 - val_rmse: 1.7340\n",
      "Epoch 310/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 11.4865 - rmse: 3.2834 - val_loss: 4.8160 - val_rmse: 1.9328\n",
      "Epoch 311/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 11.4930 - rmse: 3.2837 - val_loss: 4.2399 - val_rmse: 1.7804\n",
      "Epoch 312/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.4169 - rmse: 3.2734 - val_loss: 4.7109 - val_rmse: 1.9102\n",
      "Epoch 313/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.3536 - rmse: 3.2632 - val_loss: 4.6923 - val_rmse: 1.9033\n",
      "Epoch 314/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 11.3633 - rmse: 3.2622 - val_loss: 4.0321 - val_rmse: 1.7340\n",
      "Epoch 315/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 11.3062 - rmse: 3.2577 - val_loss: 4.0196 - val_rmse: 1.7292\n",
      "Epoch 316/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 11.2643 - rmse: 3.2539 - val_loss: 4.2961 - val_rmse: 1.8027\n",
      "Epoch 317/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 11.2294 - rmse: 3.2453 - val_loss: 5.9482 - val_rmse: 2.1963\n",
      "Epoch 318/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 11.3536 - rmse: 3.2622 - val_loss: 4.9775 - val_rmse: 1.9692\n",
      "Epoch 319/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 11.2153 - rmse: 3.2413 - val_loss: 4.5814 - val_rmse: 1.8721\n",
      "Epoch 320/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.1501 - rmse: 3.2315 - val_loss: 4.3945 - val_rmse: 1.8285\n",
      "Epoch 321/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.2476 - rmse: 3.2481 - val_loss: 5.1090 - val_rmse: 2.0093\n",
      "Epoch 322/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 11.1331 - rmse: 3.2325 - val_loss: 4.3043 - val_rmse: 1.8105\n",
      "Epoch 323/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 11.1009 - rmse: 3.2267 - val_loss: 4.5740 - val_rmse: 1.8791\n",
      "Epoch 324/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.9433 - rmse: 3.2036 - val_loss: 4.5464 - val_rmse: 1.8738\n",
      "Epoch 325/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 11.0117 - rmse: 3.2132 - val_loss: 4.0365 - val_rmse: 1.7360\n",
      "Epoch 326/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.9486 - rmse: 3.2032 - val_loss: 4.1580 - val_rmse: 1.7682\n",
      "Epoch 327/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 10.8695 - rmse: 3.1956 - val_loss: 4.1734 - val_rmse: 1.7744\n",
      "Epoch 328/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 10.8140 - rmse: 3.1849 - val_loss: 4.0349 - val_rmse: 1.7344\n",
      "Epoch 329/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 10.8481 - rmse: 3.1901 - val_loss: 4.3745 - val_rmse: 1.8254\n",
      "Epoch 330/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.7332 - rmse: 3.1704 - val_loss: 4.0798 - val_rmse: 1.7467\n",
      "Epoch 331/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 10.7147 - rmse: 3.1708 - val_loss: 4.0209 - val_rmse: 1.7323\n",
      "Epoch 332/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 10.7393 - rmse: 3.1769 - val_loss: 5.9184 - val_rmse: 2.2006\n",
      "Epoch 333/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.7046 - rmse: 3.1680 - val_loss: 5.7215 - val_rmse: 2.1471\n",
      "Epoch 334/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.6579 - rmse: 3.1606 - val_loss: 5.0843 - val_rmse: 2.0077\n",
      "Epoch 335/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 10.5346 - rmse: 3.1436 - val_loss: 4.2275 - val_rmse: 1.7856\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.5334 - rmse: 3.1445 - val_loss: 4.2610 - val_rmse: 1.7981\n",
      "Epoch 337/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.4496 - rmse: 3.1316 - val_loss: 4.4219 - val_rmse: 1.8402\n",
      "Epoch 338/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.4599 - rmse: 3.1317 - val_loss: 4.0247 - val_rmse: 1.7293\n",
      "Epoch 339/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.3930 - rmse: 3.1176 - val_loss: 6.1727 - val_rmse: 2.2597\n",
      "Epoch 340/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 10.4487 - rmse: 3.1278 - val_loss: 4.4199 - val_rmse: 1.8347\n",
      "Epoch 341/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.3979 - rmse: 3.1208 - val_loss: 4.0203 - val_rmse: 1.7336\n",
      "Epoch 342/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 10.3470 - rmse: 3.1151 - val_loss: 5.5650 - val_rmse: 2.1126\n",
      "Epoch 343/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 10.3955 - rmse: 3.1218 - val_loss: 4.0101 - val_rmse: 1.7287\n",
      "Epoch 344/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 10.1942 - rmse: 3.0919 - val_loss: 4.2408 - val_rmse: 1.7886\n",
      "Epoch 345/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 10.1981 - rmse: 3.0930 - val_loss: 4.3473 - val_rmse: 1.8178\n",
      "Epoch 346/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.2387 - rmse: 3.0968 - val_loss: 5.1770 - val_rmse: 2.0258\n",
      "Epoch 347/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 10.2573 - rmse: 3.1003 - val_loss: 5.5112 - val_rmse: 2.1119\n",
      "Epoch 348/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 10.1551 - rmse: 3.0864 - val_loss: 4.1131 - val_rmse: 1.7587\n",
      "Epoch 349/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 10.1639 - rmse: 3.0844 - val_loss: 4.0034 - val_rmse: 1.7297\n",
      "Epoch 350/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 10.0616 - rmse: 3.0709 - val_loss: 4.0248 - val_rmse: 1.7328\n",
      "Epoch 351/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 9.9735 - rmse: 3.0566 - val_loss: 4.8277 - val_rmse: 1.9465\n",
      "Epoch 352/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 9.9702 - rmse: 3.0573 - val_loss: 3.9771 - val_rmse: 1.7203\n",
      "Epoch 353/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 9.9625 - rmse: 3.0571 - val_loss: 4.0277 - val_rmse: 1.7342\n",
      "Epoch 354/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 9.9020 - rmse: 3.0432 - val_loss: 4.3822 - val_rmse: 1.8275\n",
      "Epoch 355/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 9.9493 - rmse: 3.0535 - val_loss: 4.4374 - val_rmse: 1.8411\n",
      "Epoch 356/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.9200 - rmse: 3.0500 - val_loss: 4.2688 - val_rmse: 1.8047\n",
      "Epoch 357/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.9121 - rmse: 3.0457 - val_loss: 5.3533 - val_rmse: 2.0620\n",
      "Epoch 358/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 9.9121 - rmse: 3.0445 - val_loss: 3.9993 - val_rmse: 1.7253\n",
      "Epoch 359/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 9.7906 - rmse: 3.0302 - val_loss: 4.3911 - val_rmse: 1.8258\n",
      "Epoch 360/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 9.7859 - rmse: 3.0284 - val_loss: 4.1034 - val_rmse: 1.7594\n",
      "Epoch 361/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.6870 - rmse: 3.0126 - val_loss: 5.1882 - val_rmse: 2.0316\n",
      "Epoch 362/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 9.7181 - rmse: 3.0135 - val_loss: 4.3759 - val_rmse: 1.8293\n",
      "Epoch 363/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.6869 - rmse: 3.0140 - val_loss: 4.7743 - val_rmse: 1.9295\n",
      "Epoch 364/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 9.5281 - rmse: 2.9873 - val_loss: 3.9404 - val_rmse: 1.7121\n",
      "Epoch 365/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 9.6325 - rmse: 3.0056 - val_loss: 4.5838 - val_rmse: 1.8803\n",
      "Epoch 366/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 9.5889 - rmse: 2.9994 - val_loss: 3.9981 - val_rmse: 1.7266\n",
      "Epoch 367/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.4982 - rmse: 2.9823 - val_loss: 4.4507 - val_rmse: 1.8530\n",
      "Epoch 368/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.5100 - rmse: 2.9867 - val_loss: 4.1373 - val_rmse: 1.7682\n",
      "Epoch 369/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.4610 - rmse: 2.9755 - val_loss: 4.0951 - val_rmse: 1.7581\n",
      "Epoch 370/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 9.4043 - rmse: 2.9670 - val_loss: 3.9035 - val_rmse: 1.7008\n",
      "Epoch 371/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 9.4121 - rmse: 2.9734 - val_loss: 3.9912 - val_rmse: 1.7280\n",
      "Epoch 372/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 9.3789 - rmse: 2.9685 - val_loss: 4.6729 - val_rmse: 1.9005\n",
      "Epoch 373/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.3073 - rmse: 2.9535 - val_loss: 4.1536 - val_rmse: 1.7726\n",
      "Epoch 374/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.2756 - rmse: 2.9461 - val_loss: 4.3365 - val_rmse: 1.8236\n",
      "Epoch 375/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.2876 - rmse: 2.9483 - val_loss: 5.0372 - val_rmse: 1.9985\n",
      "Epoch 376/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.3021 - rmse: 2.9531 - val_loss: 3.9213 - val_rmse: 1.7114\n",
      "Epoch 377/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.2099 - rmse: 2.9379 - val_loss: 6.9868 - val_rmse: 2.4255\n",
      "Epoch 378/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.2960 - rmse: 2.9481 - val_loss: 4.3099 - val_rmse: 1.8139\n",
      "Epoch 379/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 9.1476 - rmse: 2.9280 - val_loss: 4.5144 - val_rmse: 1.8690\n",
      "Epoch 380/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 9.0268 - rmse: 2.9079 - val_loss: 5.0084 - val_rmse: 1.9945\n",
      "Epoch 381/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 9.0832 - rmse: 2.9168 - val_loss: 4.0196 - val_rmse: 1.7379\n",
      "Epoch 382/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 9.1221 - rmse: 2.9234 - val_loss: 6.6320 - val_rmse: 2.3592\n",
      "Epoch 383/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 9.1915 - rmse: 2.9349 - val_loss: 4.6682 - val_rmse: 1.9084\n",
      "Epoch 384/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 9.0554 - rmse: 2.9129 - val_loss: 4.5386 - val_rmse: 1.8708\n",
      "Epoch 385/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 9.0209 - rmse: 2.9079 - val_loss: 4.5308 - val_rmse: 1.8745\n",
      "Epoch 386/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 9.0220 - rmse: 2.9078 - val_loss: 4.0160 - val_rmse: 1.7348\n",
      "Epoch 387/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.9506 - rmse: 2.8965 - val_loss: 4.3425 - val_rmse: 1.8106\n",
      "Epoch 388/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 8.9445 - rmse: 2.8936 - val_loss: 6.5577 - val_rmse: 2.3352\n",
      "Epoch 389/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 8.9245 - rmse: 2.8880 - val_loss: 5.7990 - val_rmse: 2.1796\n",
      "Epoch 390/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.9379 - rmse: 2.8910 - val_loss: 4.5581 - val_rmse: 1.8837\n",
      "Epoch 391/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.8798 - rmse: 2.8843 - val_loss: 3.9189 - val_rmse: 1.7055\n",
      "Epoch 392/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.8147 - rmse: 2.8748 - val_loss: 3.9653 - val_rmse: 1.7229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 8.7685 - rmse: 2.8671 - val_loss: 4.3598 - val_rmse: 1.8284\n",
      "Epoch 394/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 8.8707 - rmse: 2.8818 - val_loss: 3.8685 - val_rmse: 1.6949\n",
      "Epoch 395/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.7821 - rmse: 2.8683 - val_loss: 4.0571 - val_rmse: 1.7491\n",
      "Epoch 396/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.6920 - rmse: 2.8580 - val_loss: 5.8639 - val_rmse: 2.1878\n",
      "Epoch 397/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 8.6907 - rmse: 2.8544 - val_loss: 5.0837 - val_rmse: 2.0144\n",
      "Epoch 398/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.6490 - rmse: 2.8449 - val_loss: 5.0488 - val_rmse: 1.9935\n",
      "Epoch 399/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.6384 - rmse: 2.8470 - val_loss: 4.4545 - val_rmse: 1.8573\n",
      "Epoch 400/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 8.6108 - rmse: 2.8419 - val_loss: 3.8521 - val_rmse: 1.6901\n",
      "Epoch 401/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 8.5446 - rmse: 2.8332 - val_loss: 4.3787 - val_rmse: 1.8273\n",
      "Epoch 402/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.5185 - rmse: 2.8277 - val_loss: 4.4843 - val_rmse: 1.8572\n",
      "Epoch 403/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.5834 - rmse: 2.8328 - val_loss: 5.7249 - val_rmse: 2.1631\n",
      "Epoch 404/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 8.5101 - rmse: 2.8221 - val_loss: 4.9185 - val_rmse: 1.9702\n",
      "Epoch 405/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.5119 - rmse: 2.8196 - val_loss: 4.9710 - val_rmse: 1.9821\n",
      "Epoch 406/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.4736 - rmse: 2.8189 - val_loss: 4.7536 - val_rmse: 1.9318\n",
      "Epoch 407/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.4621 - rmse: 2.8145 - val_loss: 4.0590 - val_rmse: 1.7451\n",
      "Epoch 408/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.3740 - rmse: 2.8021 - val_loss: 4.2918 - val_rmse: 1.8096\n",
      "Epoch 409/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.3583 - rmse: 2.8001 - val_loss: 4.4839 - val_rmse: 1.8637\n",
      "Epoch 410/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 8.3588 - rmse: 2.7982 - val_loss: 5.0090 - val_rmse: 1.9935\n",
      "Epoch 411/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.3732 - rmse: 2.7987 - val_loss: 5.1253 - val_rmse: 2.0192\n",
      "Epoch 412/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.3251 - rmse: 2.7900 - val_loss: 4.6840 - val_rmse: 1.9124\n",
      "Epoch 413/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.2644 - rmse: 2.7823 - val_loss: 4.7613 - val_rmse: 1.9351\n",
      "Epoch 414/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.3258 - rmse: 2.7919 - val_loss: 4.4628 - val_rmse: 1.8620\n",
      "Epoch 415/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.2549 - rmse: 2.7833 - val_loss: 3.8810 - val_rmse: 1.7015\n",
      "Epoch 416/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 8.1983 - rmse: 2.7726 - val_loss: 4.5901 - val_rmse: 1.8930\n",
      "Epoch 417/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.2080 - rmse: 2.7698 - val_loss: 4.6248 - val_rmse: 1.8965\n",
      "Epoch 418/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 8.2361 - rmse: 2.7743 - val_loss: 4.1392 - val_rmse: 1.7739\n",
      "Epoch 419/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.0980 - rmse: 2.7546 - val_loss: 3.9774 - val_rmse: 1.7280\n",
      "Epoch 420/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 8.1766 - rmse: 2.7702 - val_loss: 4.1834 - val_rmse: 1.7882\n",
      "Epoch 421/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 8.0116 - rmse: 2.7408 - val_loss: 4.8496 - val_rmse: 1.9522\n",
      "Epoch 422/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 8.0447 - rmse: 2.7465 - val_loss: 4.6340 - val_rmse: 1.9051\n",
      "Epoch 423/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 8.1159 - rmse: 2.7594 - val_loss: 3.8593 - val_rmse: 1.6957\n",
      "Epoch 424/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 8.0114 - rmse: 2.7379 - val_loss: 4.7123 - val_rmse: 1.9173\n",
      "Epoch 425/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 8.0071 - rmse: 2.7385 - val_loss: 3.9609 - val_rmse: 1.7227\n",
      "Epoch 426/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 8.0310 - rmse: 2.7399 - val_loss: 4.6492 - val_rmse: 1.9040\n",
      "Epoch 427/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 7.9698 - rmse: 2.7326 - val_loss: 4.0749 - val_rmse: 1.7580\n",
      "Epoch 428/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.8998 - rmse: 2.7225 - val_loss: 4.5679 - val_rmse: 1.8831\n",
      "Epoch 429/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.8962 - rmse: 2.7180 - val_loss: 3.8582 - val_rmse: 1.6947\n",
      "Epoch 430/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.9226 - rmse: 2.7254 - val_loss: 4.5467 - val_rmse: 1.8806\n",
      "Epoch 431/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 7.9570 - rmse: 2.7304 - val_loss: 4.3762 - val_rmse: 1.8366\n",
      "Epoch 432/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 7.7749 - rmse: 2.7004 - val_loss: 4.8027 - val_rmse: 1.9506\n",
      "Epoch 433/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.8837 - rmse: 2.7145 - val_loss: 4.6788 - val_rmse: 1.9123\n",
      "Epoch 434/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.8693 - rmse: 2.7161 - val_loss: 3.9207 - val_rmse: 1.7136\n",
      "Epoch 435/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.7139 - rmse: 2.6908 - val_loss: 4.0756 - val_rmse: 1.7451\n",
      "Epoch 436/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 7.7073 - rmse: 2.6895 - val_loss: 3.9797 - val_rmse: 1.7277\n",
      "Epoch 437/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 7.7498 - rmse: 2.6959 - val_loss: 3.8247 - val_rmse: 1.6851\n",
      "Epoch 438/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 7.6800 - rmse: 2.6864 - val_loss: 4.4217 - val_rmse: 1.8476\n",
      "Epoch 439/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 7.7419 - rmse: 2.6930 - val_loss: 4.7249 - val_rmse: 1.9265\n",
      "Epoch 440/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 7.7001 - rmse: 2.6843 - val_loss: 3.8562 - val_rmse: 1.6950\n",
      "Epoch 441/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 7.6761 - rmse: 2.6832 - val_loss: 4.3520 - val_rmse: 1.8232\n",
      "Epoch 442/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.6597 - rmse: 2.6795 - val_loss: 4.2698 - val_rmse: 1.8104\n",
      "Epoch 443/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 7.5815 - rmse: 2.6664 - val_loss: 5.9686 - val_rmse: 2.2208\n",
      "Epoch 444/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.7153 - rmse: 2.6867 - val_loss: 4.2781 - val_rmse: 1.8064\n",
      "Epoch 445/1000\n",
      "5639/5639 [==============================] - 3s 560us/sample - loss: 7.6102 - rmse: 2.6714 - val_loss: 3.8036 - val_rmse: 1.6799\n",
      "Epoch 446/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 7.5559 - rmse: 2.6656 - val_loss: 4.6740 - val_rmse: 1.9136\n",
      "Epoch 447/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 7.5379 - rmse: 2.6571 - val_loss: 3.8282 - val_rmse: 1.6876\n",
      "Epoch 448/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.5416 - rmse: 2.6597 - val_loss: 4.3787 - val_rmse: 1.8350\n",
      "Epoch 449/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 7.4072 - rmse: 2.6345 - val_loss: 4.4454 - val_rmse: 1.8551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.5874 - rmse: 2.6652 - val_loss: 3.8981 - val_rmse: 1.7082\n",
      "Epoch 451/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 7.4349 - rmse: 2.6428 - val_loss: 3.9771 - val_rmse: 1.7284\n",
      "Epoch 452/1000\n",
      "5639/5639 [==============================] - 3s 552us/sample - loss: 7.3998 - rmse: 2.6355 - val_loss: 3.8012 - val_rmse: 1.6796\n",
      "Epoch 453/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 7.3787 - rmse: 2.6299 - val_loss: 4.3647 - val_rmse: 1.8339\n",
      "Epoch 454/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.3215 - rmse: 2.6199 - val_loss: 4.3037 - val_rmse: 1.8136\n",
      "Epoch 455/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.3947 - rmse: 2.6327 - val_loss: 4.6978 - val_rmse: 1.9184\n",
      "Epoch 456/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 7.3584 - rmse: 2.6261 - val_loss: 4.0709 - val_rmse: 1.7539\n",
      "Epoch 457/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 7.3077 - rmse: 2.6186 - val_loss: 4.0269 - val_rmse: 1.7432\n",
      "Epoch 458/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.3170 - rmse: 2.6175 - val_loss: 4.1131 - val_rmse: 1.7614\n",
      "Epoch 459/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.3329 - rmse: 2.6196 - val_loss: 4.3569 - val_rmse: 1.8322\n",
      "Epoch 460/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 7.2273 - rmse: 2.6036 - val_loss: 4.4691 - val_rmse: 1.8616\n",
      "Epoch 461/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.2650 - rmse: 2.6078 - val_loss: 4.4069 - val_rmse: 1.8408\n",
      "Epoch 462/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 7.1871 - rmse: 2.5955 - val_loss: 4.0396 - val_rmse: 1.7407\n",
      "Epoch 463/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 7.2054 - rmse: 2.5973 - val_loss: 4.2141 - val_rmse: 1.7881\n",
      "Epoch 464/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 7.1653 - rmse: 2.5900 - val_loss: 3.8007 - val_rmse: 1.6799\n",
      "Epoch 465/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.1620 - rmse: 2.5917 - val_loss: 4.0647 - val_rmse: 1.7543\n",
      "Epoch 466/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 7.1252 - rmse: 2.5832 - val_loss: 5.5903 - val_rmse: 2.1347\n",
      "Epoch 467/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.1757 - rmse: 2.5917 - val_loss: 4.1155 - val_rmse: 1.7662\n",
      "Epoch 468/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.0952 - rmse: 2.5772 - val_loss: 3.9206 - val_rmse: 1.7124\n",
      "Epoch 469/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 7.0990 - rmse: 2.5781 - val_loss: 4.2482 - val_rmse: 1.8006\n",
      "Epoch 470/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 7.1112 - rmse: 2.5804 - val_loss: 4.7984 - val_rmse: 1.9420\n",
      "Epoch 471/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 7.1332 - rmse: 2.5833 - val_loss: 3.8302 - val_rmse: 1.6859\n",
      "Epoch 472/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.0825 - rmse: 2.5755 - val_loss: 5.3630 - val_rmse: 2.0715\n",
      "Epoch 473/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.0603 - rmse: 2.5718 - val_loss: 4.1161 - val_rmse: 1.7644\n",
      "Epoch 474/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 7.0156 - rmse: 2.5656 - val_loss: 3.8066 - val_rmse: 1.6794\n",
      "Epoch 475/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.9529 - rmse: 2.5528 - val_loss: 4.3510 - val_rmse: 1.8284\n",
      "Epoch 476/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 7.0032 - rmse: 2.5587 - val_loss: 4.1835 - val_rmse: 1.7824\n",
      "Epoch 477/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 6.9317 - rmse: 2.5494 - val_loss: 4.5247 - val_rmse: 1.8751\n",
      "Epoch 478/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.9210 - rmse: 2.5466 - val_loss: 4.7066 - val_rmse: 1.9218\n",
      "Epoch 479/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.9363 - rmse: 2.5454 - val_loss: 3.8977 - val_rmse: 1.7093\n",
      "Epoch 480/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.8922 - rmse: 2.5399 - val_loss: 4.0535 - val_rmse: 1.7461\n",
      "Epoch 481/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.9003 - rmse: 2.5427 - val_loss: 4.2070 - val_rmse: 1.7951\n",
      "Epoch 482/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.8299 - rmse: 2.5279 - val_loss: 4.1967 - val_rmse: 1.7862\n",
      "Epoch 483/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.8199 - rmse: 2.5278 - val_loss: 4.1498 - val_rmse: 1.7695\n",
      "Epoch 484/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.8755 - rmse: 2.5363 - val_loss: 5.3678 - val_rmse: 2.0797\n",
      "Epoch 485/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.8268 - rmse: 2.5291 - val_loss: 4.0986 - val_rmse: 1.7638\n",
      "Epoch 486/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.8070 - rmse: 2.5251 - val_loss: 4.3121 - val_rmse: 1.8213\n",
      "Epoch 487/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 6.7446 - rmse: 2.5119 - val_loss: 3.7863 - val_rmse: 1.6764\n",
      "Epoch 488/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.7652 - rmse: 2.5173 - val_loss: 3.7985 - val_rmse: 1.6772\n",
      "Epoch 489/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.7244 - rmse: 2.5088 - val_loss: 5.5812 - val_rmse: 2.1324\n",
      "Epoch 490/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.7581 - rmse: 2.5148 - val_loss: 4.3163 - val_rmse: 1.8195\n",
      "Epoch 491/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 6.7591 - rmse: 2.5151 - val_loss: 4.1372 - val_rmse: 1.7690\n",
      "Epoch 492/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.6478 - rmse: 2.4944 - val_loss: 4.3327 - val_rmse: 1.8243\n",
      "Epoch 493/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 6.6976 - rmse: 2.5046 - val_loss: 3.7883 - val_rmse: 1.6737\n",
      "Epoch 494/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.6661 - rmse: 2.4981 - val_loss: 4.6656 - val_rmse: 1.9101\n",
      "Epoch 495/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 6.6673 - rmse: 2.4955 - val_loss: 3.7842 - val_rmse: 1.6717\n",
      "Epoch 496/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.6302 - rmse: 2.4912 - val_loss: 4.3672 - val_rmse: 1.8282\n",
      "Epoch 497/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.6290 - rmse: 2.4901 - val_loss: 3.8530 - val_rmse: 1.6915\n",
      "Epoch 498/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.6322 - rmse: 2.4949 - val_loss: 4.5107 - val_rmse: 1.8678\n",
      "Epoch 499/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.6148 - rmse: 2.4916 - val_loss: 5.1987 - val_rmse: 2.0417\n",
      "Epoch 500/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.5925 - rmse: 2.4824 - val_loss: 4.4073 - val_rmse: 1.8336\n",
      "Epoch 501/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.6095 - rmse: 2.4861 - val_loss: 3.7926 - val_rmse: 1.6728\n",
      "Epoch 502/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.5438 - rmse: 2.4775 - val_loss: 5.6920 - val_rmse: 2.1505\n",
      "Epoch 503/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.5980 - rmse: 2.4862 - val_loss: 4.2295 - val_rmse: 1.8019\n",
      "Epoch 504/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 6.4940 - rmse: 2.4666 - val_loss: 5.0153 - val_rmse: 1.9958\n",
      "Epoch 505/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.5342 - rmse: 2.4717 - val_loss: 3.9974 - val_rmse: 1.7321\n",
      "Epoch 506/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.4830 - rmse: 2.4627 - val_loss: 3.9323 - val_rmse: 1.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.4249 - rmse: 2.4546 - val_loss: 5.0852 - val_rmse: 2.0165\n",
      "Epoch 508/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 6.4836 - rmse: 2.4641 - val_loss: 3.7581 - val_rmse: 1.6641\n",
      "Epoch 509/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 6.4189 - rmse: 2.4522 - val_loss: 3.9310 - val_rmse: 1.7128\n",
      "Epoch 510/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.3843 - rmse: 2.4456 - val_loss: 3.7763 - val_rmse: 1.6729\n",
      "Epoch 511/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 6.3556 - rmse: 2.4440 - val_loss: 5.6784 - val_rmse: 2.1484\n",
      "Epoch 512/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.4517 - rmse: 2.4553 - val_loss: 3.9387 - val_rmse: 1.7201\n",
      "Epoch 513/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.3644 - rmse: 2.4410 - val_loss: 6.7651 - val_rmse: 2.3969\n",
      "Epoch 514/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.4180 - rmse: 2.4521 - val_loss: 4.9451 - val_rmse: 1.9863\n",
      "Epoch 515/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.4259 - rmse: 2.4525 - val_loss: 4.1546 - val_rmse: 1.7739\n",
      "Epoch 516/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.3598 - rmse: 2.4403 - val_loss: 3.7750 - val_rmse: 1.6752\n",
      "Epoch 517/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 6.3208 - rmse: 2.4317 - val_loss: 4.3929 - val_rmse: 1.8467\n",
      "Epoch 518/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.3097 - rmse: 2.4317 - val_loss: 3.8949 - val_rmse: 1.7060\n",
      "Epoch 519/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.2783 - rmse: 2.4237 - val_loss: 3.8674 - val_rmse: 1.6994\n",
      "Epoch 520/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.3031 - rmse: 2.4282 - val_loss: 5.9454 - val_rmse: 2.2095\n",
      "Epoch 521/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.3214 - rmse: 2.4303 - val_loss: 3.7700 - val_rmse: 1.6718\n",
      "Epoch 522/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.2544 - rmse: 2.4219 - val_loss: 4.8047 - val_rmse: 1.9502\n",
      "Epoch 523/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.2689 - rmse: 2.4212 - val_loss: 4.0127 - val_rmse: 1.7425\n",
      "Epoch 524/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 6.2576 - rmse: 2.4224 - val_loss: 3.8010 - val_rmse: 1.6776\n",
      "Epoch 525/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 6.2308 - rmse: 2.4158 - val_loss: 3.7205 - val_rmse: 1.6558\n",
      "Epoch 526/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 6.1820 - rmse: 2.4059 - val_loss: 4.3354 - val_rmse: 1.8273\n",
      "Epoch 527/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.1862 - rmse: 2.4085 - val_loss: 5.1117 - val_rmse: 2.0157\n",
      "Epoch 528/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 6.1182 - rmse: 2.3917 - val_loss: 5.4056 - val_rmse: 2.0901\n",
      "Epoch 529/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.2305 - rmse: 2.4136 - val_loss: 3.7780 - val_rmse: 1.6729\n",
      "Epoch 530/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 6.1561 - rmse: 2.3998 - val_loss: 3.8939 - val_rmse: 1.7068\n",
      "Epoch 531/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.1206 - rmse: 2.3946 - val_loss: 4.0260 - val_rmse: 1.7383\n",
      "Epoch 532/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.0979 - rmse: 2.3894 - val_loss: 4.6035 - val_rmse: 1.8972\n",
      "Epoch 533/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.1092 - rmse: 2.3914 - val_loss: 3.7499 - val_rmse: 1.6647\n",
      "Epoch 534/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.0132 - rmse: 2.3736 - val_loss: 4.0408 - val_rmse: 1.7427\n",
      "Epoch 535/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 6.0519 - rmse: 2.3823 - val_loss: 4.9173 - val_rmse: 1.9741\n",
      "Epoch 536/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.0912 - rmse: 2.3864 - val_loss: 4.5122 - val_rmse: 1.8714\n",
      "Epoch 537/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 6.0422 - rmse: 2.3779 - val_loss: 4.0336 - val_rmse: 1.7459\n",
      "Epoch 538/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.9365 - rmse: 2.3598 - val_loss: 3.9387 - val_rmse: 1.7144\n",
      "Epoch 539/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.9451 - rmse: 2.3623 - val_loss: 3.9122 - val_rmse: 1.7095\n",
      "Epoch 540/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 6.0624 - rmse: 2.3829 - val_loss: 3.9362 - val_rmse: 1.7201\n",
      "Epoch 541/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 6.0535 - rmse: 2.3802 - val_loss: 3.7738 - val_rmse: 1.6676\n",
      "Epoch 542/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 6.0363 - rmse: 2.3741 - val_loss: 4.8002 - val_rmse: 1.9381\n",
      "Epoch 543/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.9227 - rmse: 2.3544 - val_loss: 4.6407 - val_rmse: 1.9015\n",
      "Epoch 544/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.9593 - rmse: 2.3604 - val_loss: 4.9118 - val_rmse: 1.9722\n",
      "Epoch 545/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.9526 - rmse: 2.3589 - val_loss: 3.8302 - val_rmse: 1.6844\n",
      "Epoch 546/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.9106 - rmse: 2.3529 - val_loss: 3.9140 - val_rmse: 1.7089\n",
      "Epoch 547/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.9267 - rmse: 2.3565 - val_loss: 3.7330 - val_rmse: 1.6612\n",
      "Epoch 548/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.9673 - rmse: 2.3647 - val_loss: 4.5349 - val_rmse: 1.8773\n",
      "Epoch 549/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.9147 - rmse: 2.3507 - val_loss: 4.0128 - val_rmse: 1.7369\n",
      "Epoch 550/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.8310 - rmse: 2.3359 - val_loss: 3.9537 - val_rmse: 1.7272\n",
      "Epoch 551/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.8729 - rmse: 2.3443 - val_loss: 3.8957 - val_rmse: 1.7065\n",
      "Epoch 552/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.8430 - rmse: 2.3393 - val_loss: 3.7689 - val_rmse: 1.6685\n",
      "Epoch 553/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.8159 - rmse: 2.3336 - val_loss: 3.7437 - val_rmse: 1.6615\n",
      "Epoch 554/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.8181 - rmse: 2.3323 - val_loss: 4.4004 - val_rmse: 1.8452\n",
      "Epoch 555/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 5.8093 - rmse: 2.3325 - val_loss: 3.7041 - val_rmse: 1.6522\n",
      "Epoch 556/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 5.7524 - rmse: 2.3226 - val_loss: 5.0640 - val_rmse: 2.0123\n",
      "Epoch 557/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.8017 - rmse: 2.3313 - val_loss: 5.7130 - val_rmse: 2.1694\n",
      "Epoch 558/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.8767 - rmse: 2.3434 - val_loss: 4.3764 - val_rmse: 1.8437\n",
      "Epoch 559/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.7312 - rmse: 2.3163 - val_loss: 5.0091 - val_rmse: 2.0007\n",
      "Epoch 560/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 5.8023 - rmse: 2.3288 - val_loss: 4.3789 - val_rmse: 1.8386\n",
      "Epoch 561/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.7583 - rmse: 2.3215 - val_loss: 3.8009 - val_rmse: 1.6812\n",
      "Epoch 562/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.7384 - rmse: 2.3204 - val_loss: 4.6463 - val_rmse: 1.9075\n",
      "Epoch 563/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.7774 - rmse: 2.3204 - val_loss: 4.0312 - val_rmse: 1.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.7512 - rmse: 2.3201 - val_loss: 3.9001 - val_rmse: 1.7147\n",
      "Epoch 565/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.6739 - rmse: 2.3032 - val_loss: 4.1926 - val_rmse: 1.7859\n",
      "Epoch 566/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.6937 - rmse: 2.3089 - val_loss: 4.4657 - val_rmse: 1.8609\n",
      "Epoch 567/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.6952 - rmse: 2.3103 - val_loss: 3.8657 - val_rmse: 1.6968\n",
      "Epoch 568/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.5910 - rmse: 2.2908 - val_loss: 4.8918 - val_rmse: 1.9681\n",
      "Epoch 569/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.6876 - rmse: 2.3062 - val_loss: 3.9917 - val_rmse: 1.7363\n",
      "Epoch 570/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.6240 - rmse: 2.2916 - val_loss: 3.8812 - val_rmse: 1.7050\n",
      "Epoch 571/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.5836 - rmse: 2.2856 - val_loss: 3.8451 - val_rmse: 1.6916\n",
      "Epoch 572/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.6360 - rmse: 2.2991 - val_loss: 5.4770 - val_rmse: 2.1122\n",
      "Epoch 573/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.7354 - rmse: 2.3158 - val_loss: 4.5184 - val_rmse: 1.8759\n",
      "Epoch 574/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.5965 - rmse: 2.2862 - val_loss: 4.5013 - val_rmse: 1.8673\n",
      "Epoch 575/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.6642 - rmse: 2.2995 - val_loss: 4.1763 - val_rmse: 1.7856\n",
      "Epoch 576/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.6105 - rmse: 2.2907 - val_loss: 4.3220 - val_rmse: 1.8190\n",
      "Epoch 577/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 5.5433 - rmse: 2.2737 - val_loss: 3.7021 - val_rmse: 1.6493\n",
      "Epoch 578/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.5201 - rmse: 2.2720 - val_loss: 3.7672 - val_rmse: 1.6695\n",
      "Epoch 579/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.4950 - rmse: 2.2699 - val_loss: 4.7598 - val_rmse: 1.9247\n",
      "Epoch 580/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 5.5401 - rmse: 2.2784 - val_loss: 5.3717 - val_rmse: 2.0855\n",
      "Epoch 581/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.5164 - rmse: 2.2718 - val_loss: 4.6842 - val_rmse: 1.9181\n",
      "Epoch 582/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 5.5364 - rmse: 2.2743 - val_loss: 4.6361 - val_rmse: 1.9078\n",
      "Epoch 583/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 5.4748 - rmse: 2.2624 - val_loss: 4.2533 - val_rmse: 1.8081\n",
      "Epoch 584/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.5918 - rmse: 2.2879 - val_loss: 4.0265 - val_rmse: 1.7430\n",
      "Epoch 585/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.4035 - rmse: 2.2478 - val_loss: 4.0392 - val_rmse: 1.7477\n",
      "Epoch 586/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 5.4160 - rmse: 2.2508 - val_loss: 3.7052 - val_rmse: 1.6488\n",
      "Epoch 587/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 5.4137 - rmse: 2.2522 - val_loss: 4.0568 - val_rmse: 1.7486\n",
      "Epoch 588/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.3501 - rmse: 2.2390 - val_loss: 4.6831 - val_rmse: 1.9193\n",
      "Epoch 589/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 5.4762 - rmse: 2.2628 - val_loss: 3.8550 - val_rmse: 1.6955\n",
      "Epoch 590/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.4017 - rmse: 2.2481 - val_loss: 4.0113 - val_rmse: 1.7348\n",
      "Epoch 591/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.4624 - rmse: 2.2607 - val_loss: 3.9039 - val_rmse: 1.7023\n",
      "Epoch 592/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.3943 - rmse: 2.2468 - val_loss: 3.9018 - val_rmse: 1.7065\n",
      "Epoch 593/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.4005 - rmse: 2.2477 - val_loss: 3.7815 - val_rmse: 1.6710\n",
      "Epoch 594/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.3468 - rmse: 2.2385 - val_loss: 4.1248 - val_rmse: 1.7725\n",
      "Epoch 595/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.3083 - rmse: 2.2297 - val_loss: 4.7757 - val_rmse: 1.9388\n",
      "Epoch 596/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.4044 - rmse: 2.2463 - val_loss: 3.9324 - val_rmse: 1.7175\n",
      "Epoch 597/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.3500 - rmse: 2.2352 - val_loss: 3.9153 - val_rmse: 1.7089\n",
      "Epoch 598/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.2979 - rmse: 2.2281 - val_loss: 3.7857 - val_rmse: 1.6731\n",
      "Epoch 599/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.3199 - rmse: 2.2307 - val_loss: 3.7564 - val_rmse: 1.6633\n",
      "Epoch 600/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 5.2977 - rmse: 2.2268 - val_loss: 3.7274 - val_rmse: 1.6606\n",
      "Epoch 601/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.3136 - rmse: 2.2316 - val_loss: 3.7530 - val_rmse: 1.6665\n",
      "Epoch 602/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.3267 - rmse: 2.2310 - val_loss: 5.1003 - val_rmse: 2.0155\n",
      "Epoch 603/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.3582 - rmse: 2.2377 - val_loss: 5.9471 - val_rmse: 2.2172\n",
      "Epoch 604/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.3421 - rmse: 2.2317 - val_loss: 3.9843 - val_rmse: 1.7306\n",
      "Epoch 605/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.3458 - rmse: 2.2346 - val_loss: 3.7643 - val_rmse: 1.6698\n",
      "Epoch 606/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.2663 - rmse: 2.2214 - val_loss: 3.8611 - val_rmse: 1.6959\n",
      "Epoch 607/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 5.1783 - rmse: 2.2011 - val_loss: 3.7931 - val_rmse: 1.6745\n",
      "Epoch 608/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.2422 - rmse: 2.2153 - val_loss: 5.5017 - val_rmse: 2.1172\n",
      "Epoch 609/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.2775 - rmse: 2.2212 - val_loss: 3.9500 - val_rmse: 1.7231\n",
      "Epoch 610/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.2153 - rmse: 2.2073 - val_loss: 4.4663 - val_rmse: 1.8582\n",
      "Epoch 611/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 5.1751 - rmse: 2.1987 - val_loss: 3.6883 - val_rmse: 1.6461\n",
      "Epoch 612/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 5.1751 - rmse: 2.2016 - val_loss: 4.9889 - val_rmse: 1.9939\n",
      "Epoch 613/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.1973 - rmse: 2.2033 - val_loss: 3.7474 - val_rmse: 1.6664\n",
      "Epoch 614/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.1709 - rmse: 2.1998 - val_loss: 4.1326 - val_rmse: 1.7731\n",
      "Epoch 615/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.1817 - rmse: 2.1989 - val_loss: 4.1184 - val_rmse: 1.7651\n",
      "Epoch 616/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.1141 - rmse: 2.1884 - val_loss: 4.5603 - val_rmse: 1.8846\n",
      "Epoch 617/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.1670 - rmse: 2.1924 - val_loss: 4.8419 - val_rmse: 1.9548\n",
      "Epoch 618/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.2126 - rmse: 2.2053 - val_loss: 4.1350 - val_rmse: 1.7752\n",
      "Epoch 619/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.1605 - rmse: 2.1973 - val_loss: 3.7247 - val_rmse: 1.6596\n",
      "Epoch 620/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.1152 - rmse: 2.1869 - val_loss: 3.6903 - val_rmse: 1.6502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.0951 - rmse: 2.1832 - val_loss: 3.7761 - val_rmse: 1.6744\n",
      "Epoch 622/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 5.0951 - rmse: 2.1836 - val_loss: 4.2741 - val_rmse: 1.8127\n",
      "Epoch 623/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 5.1032 - rmse: 2.1812 - val_loss: 3.7262 - val_rmse: 1.6598\n",
      "Epoch 624/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 5.0844 - rmse: 2.1786 - val_loss: 3.6430 - val_rmse: 1.6350\n",
      "Epoch 625/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 5.0747 - rmse: 2.1776 - val_loss: 4.0417 - val_rmse: 1.7530\n",
      "Epoch 626/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.0618 - rmse: 2.1763 - val_loss: 4.1672 - val_rmse: 1.7761\n",
      "Epoch 627/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 5.0731 - rmse: 2.1784 - val_loss: 5.6269 - val_rmse: 2.1437\n",
      "Epoch 628/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 5.1057 - rmse: 2.1795 - val_loss: 3.9855 - val_rmse: 1.7327\n",
      "Epoch 629/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 5.0455 - rmse: 2.1699 - val_loss: 5.1716 - val_rmse: 2.0368\n",
      "Epoch 630/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.0988 - rmse: 2.1805 - val_loss: 3.9645 - val_rmse: 1.7215\n",
      "Epoch 631/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.9917 - rmse: 2.1634 - val_loss: 3.7349 - val_rmse: 1.6588\n",
      "Epoch 632/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 5.1008 - rmse: 2.1834 - val_loss: 3.7071 - val_rmse: 1.6513\n",
      "Epoch 633/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.9867 - rmse: 2.1600 - val_loss: 4.1729 - val_rmse: 1.7813\n",
      "Epoch 634/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.9346 - rmse: 2.1453 - val_loss: 4.0076 - val_rmse: 1.7348\n",
      "Epoch 635/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 4.9360 - rmse: 2.1485 - val_loss: 3.9289 - val_rmse: 1.7165\n",
      "Epoch 636/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.9736 - rmse: 2.1564 - val_loss: 3.6684 - val_rmse: 1.6406\n",
      "Epoch 637/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.9702 - rmse: 2.1541 - val_loss: 4.1018 - val_rmse: 1.7692\n",
      "Epoch 638/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 5.0268 - rmse: 2.1663 - val_loss: 4.8077 - val_rmse: 1.9458\n",
      "Epoch 639/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.9596 - rmse: 2.1535 - val_loss: 3.9035 - val_rmse: 1.7095\n",
      "Epoch 640/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 4.9452 - rmse: 2.1497 - val_loss: 4.1351 - val_rmse: 1.7758\n",
      "Epoch 641/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8819 - rmse: 2.1378 - val_loss: 3.9466 - val_rmse: 1.7197\n",
      "Epoch 642/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8734 - rmse: 2.1317 - val_loss: 3.6438 - val_rmse: 1.6361\n",
      "Epoch 643/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8935 - rmse: 2.1384 - val_loss: 4.0254 - val_rmse: 1.7483\n",
      "Epoch 644/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8787 - rmse: 2.1355 - val_loss: 4.4913 - val_rmse: 1.8686\n",
      "Epoch 645/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.8928 - rmse: 2.1351 - val_loss: 4.2899 - val_rmse: 1.8122\n",
      "Epoch 646/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.8402 - rmse: 2.1276 - val_loss: 3.7375 - val_rmse: 1.6610\n",
      "Epoch 647/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.8651 - rmse: 2.1312 - val_loss: 3.8738 - val_rmse: 1.6990\n",
      "Epoch 648/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8207 - rmse: 2.1241 - val_loss: 3.7603 - val_rmse: 1.6645\n",
      "Epoch 649/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8432 - rmse: 2.1262 - val_loss: 4.3059 - val_rmse: 1.8206\n",
      "Epoch 650/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 4.8883 - rmse: 2.1374 - val_loss: 3.6397 - val_rmse: 1.6331\n",
      "Epoch 651/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 4.8145 - rmse: 2.1213 - val_loss: 4.8216 - val_rmse: 1.9475\n",
      "Epoch 652/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8655 - rmse: 2.1297 - val_loss: 4.2747 - val_rmse: 1.8101\n",
      "Epoch 653/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.8491 - rmse: 2.1266 - val_loss: 6.5228 - val_rmse: 2.3487\n",
      "Epoch 654/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.9647 - rmse: 2.1492 - val_loss: 3.7615 - val_rmse: 1.6634\n",
      "Epoch 655/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8140 - rmse: 2.1184 - val_loss: 4.1007 - val_rmse: 1.7664\n",
      "Epoch 656/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.9212 - rmse: 2.1425 - val_loss: 4.1796 - val_rmse: 1.7816\n",
      "Epoch 657/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.8386 - rmse: 2.1232 - val_loss: 3.7093 - val_rmse: 1.6451\n",
      "Epoch 658/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.7854 - rmse: 2.1133 - val_loss: 5.1210 - val_rmse: 2.0265\n",
      "Epoch 659/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.8502 - rmse: 2.1264 - val_loss: 3.8330 - val_rmse: 1.6852\n",
      "Epoch 660/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 4.8040 - rmse: 2.1149 - val_loss: 4.3488 - val_rmse: 1.8326\n",
      "Epoch 661/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8203 - rmse: 2.1195 - val_loss: 5.0870 - val_rmse: 2.0209\n",
      "Epoch 662/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 4.8589 - rmse: 2.1283 - val_loss: 3.7584 - val_rmse: 1.6647\n",
      "Epoch 663/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 4.7933 - rmse: 2.1134 - val_loss: 4.3528 - val_rmse: 1.8342\n",
      "Epoch 664/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8003 - rmse: 2.1159 - val_loss: 4.0722 - val_rmse: 1.7516\n",
      "Epoch 665/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 4.8180 - rmse: 2.1190 - val_loss: 3.9801 - val_rmse: 1.7322\n",
      "Epoch 666/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.7208 - rmse: 2.0978 - val_loss: 3.6921 - val_rmse: 1.6518\n",
      "Epoch 667/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.7044 - rmse: 2.0972 - val_loss: 4.4504 - val_rmse: 1.8544\n",
      "Epoch 668/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.7464 - rmse: 2.1068 - val_loss: 3.9979 - val_rmse: 1.7337\n",
      "Epoch 669/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.6904 - rmse: 2.0928 - val_loss: 5.9247 - val_rmse: 2.2126\n",
      "Epoch 670/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.8108 - rmse: 2.1144 - val_loss: 3.9896 - val_rmse: 1.7322\n",
      "Epoch 671/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.7113 - rmse: 2.0949 - val_loss: 4.1819 - val_rmse: 1.7842\n",
      "Epoch 672/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.7464 - rmse: 2.1037 - val_loss: 3.8624 - val_rmse: 1.6935\n",
      "Epoch 673/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.6332 - rmse: 2.0792 - val_loss: 4.2256 - val_rmse: 1.7950\n",
      "Epoch 674/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.7092 - rmse: 2.0945 - val_loss: 5.5021 - val_rmse: 2.1217\n",
      "Epoch 675/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.8288 - rmse: 2.1179 - val_loss: 3.7329 - val_rmse: 1.6548\n",
      "Epoch 676/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.6111 - rmse: 2.0734 - val_loss: 3.7050 - val_rmse: 1.6537\n",
      "Epoch 677/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.6945 - rmse: 2.0915 - val_loss: 3.8821 - val_rmse: 1.6972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 678/1000\n",
      "5639/5639 [==============================] - 3s 523us/sample - loss: 4.6872 - rmse: 2.0846 - val_loss: 3.8591 - val_rmse: 1.6950\n",
      "Epoch 679/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.6745 - rmse: 2.0865 - val_loss: 3.9257 - val_rmse: 1.7160\n",
      "Epoch 680/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.6355 - rmse: 2.0787 - val_loss: 4.0588 - val_rmse: 1.7517\n",
      "Epoch 681/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.6150 - rmse: 2.0761 - val_loss: 3.9277 - val_rmse: 1.7120\n",
      "Epoch 682/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.5564 - rmse: 2.0609 - val_loss: 4.4659 - val_rmse: 1.8584\n",
      "Epoch 683/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.6169 - rmse: 2.0744 - val_loss: 4.2648 - val_rmse: 1.8137\n",
      "Epoch 684/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.6365 - rmse: 2.0773 - val_loss: 5.3798 - val_rmse: 2.0897\n",
      "Epoch 685/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.6546 - rmse: 2.0802 - val_loss: 3.6559 - val_rmse: 1.6411\n",
      "Epoch 686/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.6503 - rmse: 2.0827 - val_loss: 4.8505 - val_rmse: 1.9606\n",
      "Epoch 687/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.6387 - rmse: 2.0781 - val_loss: 5.1645 - val_rmse: 2.0296\n",
      "Epoch 688/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 4.6084 - rmse: 2.0703 - val_loss: 4.0911 - val_rmse: 1.7644\n",
      "Epoch 689/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 4.6057 - rmse: 2.0715 - val_loss: 4.2865 - val_rmse: 1.8086\n",
      "Epoch 690/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 4.5645 - rmse: 2.0632 - val_loss: 3.6301 - val_rmse: 1.6318\n",
      "Epoch 691/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.5737 - rmse: 2.0651 - val_loss: 3.9770 - val_rmse: 1.7300\n",
      "Epoch 692/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.5158 - rmse: 2.0508 - val_loss: 4.1754 - val_rmse: 1.7838\n",
      "Epoch 693/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 4.5853 - rmse: 2.0692 - val_loss: 3.8354 - val_rmse: 1.6879\n",
      "Epoch 694/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.5349 - rmse: 2.0565 - val_loss: 4.2991 - val_rmse: 1.8192\n",
      "Epoch 695/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.5045 - rmse: 2.0477 - val_loss: 3.9222 - val_rmse: 1.7117\n",
      "Epoch 696/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.4885 - rmse: 2.0479 - val_loss: 4.2862 - val_rmse: 1.8136\n",
      "Epoch 697/1000\n",
      "5639/5639 [==============================] - 3s 554us/sample - loss: 4.4968 - rmse: 2.0477 - val_loss: 3.6178 - val_rmse: 1.6256\n",
      "Epoch 698/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.5260 - rmse: 2.0544 - val_loss: 4.2523 - val_rmse: 1.8014\n",
      "Epoch 699/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.5054 - rmse: 2.0474 - val_loss: 4.4330 - val_rmse: 1.8518\n",
      "Epoch 700/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.5004 - rmse: 2.0445 - val_loss: 4.1179 - val_rmse: 1.7643\n",
      "Epoch 701/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.5161 - rmse: 2.0500 - val_loss: 4.2591 - val_rmse: 1.8065\n",
      "Epoch 702/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.4223 - rmse: 2.0303 - val_loss: 3.7017 - val_rmse: 1.6459\n",
      "Epoch 703/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 4.4519 - rmse: 2.0378 - val_loss: 3.6732 - val_rmse: 1.6403\n",
      "Epoch 704/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.4305 - rmse: 2.0307 - val_loss: 3.7910 - val_rmse: 1.6744\n",
      "Epoch 705/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.4676 - rmse: 2.0386 - val_loss: 3.6372 - val_rmse: 1.6293\n",
      "Epoch 706/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.4301 - rmse: 2.0333 - val_loss: 3.6767 - val_rmse: 1.6423\n",
      "Epoch 707/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.4677 - rmse: 2.0382 - val_loss: 4.0258 - val_rmse: 1.7458\n",
      "Epoch 708/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.4568 - rmse: 2.0370 - val_loss: 3.9960 - val_rmse: 1.7307\n",
      "Epoch 709/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.4276 - rmse: 2.0311 - val_loss: 3.8064 - val_rmse: 1.6827\n",
      "Epoch 710/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.4491 - rmse: 2.0349 - val_loss: 3.7626 - val_rmse: 1.6686\n",
      "Epoch 711/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.4204 - rmse: 2.0280 - val_loss: 3.7027 - val_rmse: 1.6483\n",
      "Epoch 712/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.4635 - rmse: 2.0351 - val_loss: 4.4907 - val_rmse: 1.8672\n",
      "Epoch 713/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.4662 - rmse: 2.0373 - val_loss: 3.6458 - val_rmse: 1.6332\n",
      "Epoch 714/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 4.3662 - rmse: 2.0178 - val_loss: 3.8293 - val_rmse: 1.6887\n",
      "Epoch 715/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.4787 - rmse: 2.0373 - val_loss: 3.9060 - val_rmse: 1.7026\n",
      "Epoch 716/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.3753 - rmse: 2.0163 - val_loss: 3.9201 - val_rmse: 1.7062\n",
      "Epoch 717/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 4.3433 - rmse: 2.0112 - val_loss: 3.5909 - val_rmse: 1.6185\n",
      "Epoch 718/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 4.3810 - rmse: 2.0194 - val_loss: 3.7973 - val_rmse: 1.6751\n",
      "Epoch 719/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.4233 - rmse: 2.0253 - val_loss: 3.8994 - val_rmse: 1.7101\n",
      "Epoch 720/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 4.3572 - rmse: 2.0123 - val_loss: 3.9273 - val_rmse: 1.7099\n",
      "Epoch 721/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 4.3649 - rmse: 2.0165 - val_loss: 3.7322 - val_rmse: 1.6562\n",
      "Epoch 722/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.3166 - rmse: 2.0037 - val_loss: 4.0836 - val_rmse: 1.7534\n",
      "Epoch 723/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.3457 - rmse: 2.0083 - val_loss: 4.1331 - val_rmse: 1.7740\n",
      "Epoch 724/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.3076 - rmse: 2.0022 - val_loss: 3.8639 - val_rmse: 1.6924\n",
      "Epoch 725/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 4.3736 - rmse: 2.0169 - val_loss: 3.5725 - val_rmse: 1.6126\n",
      "Epoch 726/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.3006 - rmse: 1.9968 - val_loss: 5.4142 - val_rmse: 2.0928\n",
      "Epoch 727/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.6170 - rmse: 2.0664 - val_loss: 4.0539 - val_rmse: 1.7465\n",
      "Epoch 728/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.3971 - rmse: 2.0178 - val_loss: 4.5443 - val_rmse: 1.8795\n",
      "Epoch 729/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.3380 - rmse: 2.0048 - val_loss: 4.0632 - val_rmse: 1.7529\n",
      "Epoch 730/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.3822 - rmse: 2.0149 - val_loss: 4.0170 - val_rmse: 1.7372\n",
      "Epoch 731/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.3038 - rmse: 1.9996 - val_loss: 3.8102 - val_rmse: 1.6813\n",
      "Epoch 732/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.2705 - rmse: 1.9921 - val_loss: 3.8431 - val_rmse: 1.6925\n",
      "Epoch 733/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.3060 - rmse: 1.9997 - val_loss: 3.8970 - val_rmse: 1.7130\n",
      "Epoch 734/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.4044 - rmse: 2.0219 - val_loss: 3.8400 - val_rmse: 1.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.3134 - rmse: 1.9989 - val_loss: 4.5206 - val_rmse: 1.8796\n",
      "Epoch 736/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.3535 - rmse: 2.0066 - val_loss: 3.7253 - val_rmse: 1.6590\n",
      "Epoch 737/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.2785 - rmse: 1.9930 - val_loss: 5.1363 - val_rmse: 2.0336\n",
      "Epoch 738/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.2991 - rmse: 1.9971 - val_loss: 4.6447 - val_rmse: 1.9056\n",
      "Epoch 739/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.2950 - rmse: 1.9941 - val_loss: 3.5839 - val_rmse: 1.6194\n",
      "Epoch 740/1000\n",
      "5639/5639 [==============================] - 3s 542us/sample - loss: 4.2397 - rmse: 1.9830 - val_loss: 4.6767 - val_rmse: 1.9154\n",
      "Epoch 741/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.2777 - rmse: 1.9912 - val_loss: 3.5740 - val_rmse: 1.6140\n",
      "Epoch 742/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.2235 - rmse: 1.9794 - val_loss: 3.6778 - val_rmse: 1.6409\n",
      "Epoch 743/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 4.1553 - rmse: 1.9639 - val_loss: 3.6622 - val_rmse: 1.6391\n",
      "Epoch 744/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.1343 - rmse: 1.9630 - val_loss: 4.3002 - val_rmse: 1.8209\n",
      "Epoch 745/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.2234 - rmse: 1.9798 - val_loss: 3.8572 - val_rmse: 1.6912\n",
      "Epoch 746/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.1609 - rmse: 1.9665 - val_loss: 3.8774 - val_rmse: 1.6964\n",
      "Epoch 747/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1491 - rmse: 1.9645 - val_loss: 3.7117 - val_rmse: 1.6542\n",
      "Epoch 748/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.1471 - rmse: 1.9648 - val_loss: 3.9294 - val_rmse: 1.7103\n",
      "Epoch 749/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.1609 - rmse: 1.9652 - val_loss: 3.6734 - val_rmse: 1.6410\n",
      "Epoch 750/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1462 - rmse: 1.9642 - val_loss: 4.1444 - val_rmse: 1.7759\n",
      "Epoch 751/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.1539 - rmse: 1.9645 - val_loss: 3.5813 - val_rmse: 1.6170\n",
      "Epoch 752/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.1869 - rmse: 1.9713 - val_loss: 5.1131 - val_rmse: 2.0258\n",
      "Epoch 753/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.2324 - rmse: 1.9807 - val_loss: 4.7635 - val_rmse: 1.9392\n",
      "Epoch 754/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 4.2279 - rmse: 1.9794 - val_loss: 3.7076 - val_rmse: 1.6545\n",
      "Epoch 755/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1365 - rmse: 1.9580 - val_loss: 3.6443 - val_rmse: 1.6314\n",
      "Epoch 756/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1157 - rmse: 1.9565 - val_loss: 4.9778 - val_rmse: 1.9897\n",
      "Epoch 757/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.2594 - rmse: 1.9833 - val_loss: 3.6742 - val_rmse: 1.6393\n",
      "Epoch 758/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.1486 - rmse: 1.9620 - val_loss: 4.0268 - val_rmse: 1.7426\n",
      "Epoch 759/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1424 - rmse: 1.9606 - val_loss: 3.6109 - val_rmse: 1.6227\n",
      "Epoch 760/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 4.0368 - rmse: 1.9397 - val_loss: 3.6642 - val_rmse: 1.6374\n",
      "Epoch 761/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.1181 - rmse: 1.9532 - val_loss: 4.2414 - val_rmse: 1.8029\n",
      "Epoch 762/1000\n",
      "5639/5639 [==============================] - 3s 558us/sample - loss: 4.1931 - rmse: 1.9703 - val_loss: 3.5600 - val_rmse: 1.6053\n",
      "Epoch 763/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 4.1135 - rmse: 1.9546 - val_loss: 3.6753 - val_rmse: 1.6408\n",
      "Epoch 764/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.0711 - rmse: 1.9438 - val_loss: 3.8179 - val_rmse: 1.6915\n",
      "Epoch 765/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.0783 - rmse: 1.9485 - val_loss: 3.7659 - val_rmse: 1.6662\n",
      "Epoch 766/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 4.1025 - rmse: 1.9508 - val_loss: 4.1610 - val_rmse: 1.7774\n",
      "Epoch 767/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.0945 - rmse: 1.9488 - val_loss: 3.8572 - val_rmse: 1.6919\n",
      "Epoch 768/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.0572 - rmse: 1.9413 - val_loss: 4.0126 - val_rmse: 1.7354\n",
      "Epoch 769/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.1009 - rmse: 1.9495 - val_loss: 3.6764 - val_rmse: 1.6415\n",
      "Epoch 770/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 4.0240 - rmse: 1.9320 - val_loss: 3.6562 - val_rmse: 1.6275\n",
      "Epoch 771/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.1028 - rmse: 1.9463 - val_loss: 4.5266 - val_rmse: 1.8793\n",
      "Epoch 772/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.0883 - rmse: 1.9458 - val_loss: 3.9661 - val_rmse: 1.7244\n",
      "Epoch 773/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 4.1288 - rmse: 1.9534 - val_loss: 4.9764 - val_rmse: 1.9943\n",
      "Epoch 774/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 4.1009 - rmse: 1.9497 - val_loss: 4.9134 - val_rmse: 1.9818\n",
      "Epoch 775/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 4.1018 - rmse: 1.9456 - val_loss: 3.7123 - val_rmse: 1.6498\n",
      "Epoch 776/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.9821 - rmse: 1.9203 - val_loss: 3.5711 - val_rmse: 1.6106\n",
      "Epoch 777/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.0522 - rmse: 1.9365 - val_loss: 3.7448 - val_rmse: 1.6587\n",
      "Epoch 778/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.9992 - rmse: 1.9268 - val_loss: 4.3713 - val_rmse: 1.8429\n",
      "Epoch 779/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 4.0299 - rmse: 1.9339 - val_loss: 4.4022 - val_rmse: 1.8491\n",
      "Epoch 780/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 4.0532 - rmse: 1.9359 - val_loss: 3.5920 - val_rmse: 1.6216\n",
      "Epoch 781/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.9777 - rmse: 1.9217 - val_loss: 4.5797 - val_rmse: 1.8979\n",
      "Epoch 782/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 4.0130 - rmse: 1.9277 - val_loss: 4.9304 - val_rmse: 1.9850\n",
      "Epoch 783/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 4.0505 - rmse: 1.9334 - val_loss: 3.6277 - val_rmse: 1.6279\n",
      "Epoch 784/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.9837 - rmse: 1.9208 - val_loss: 4.5080 - val_rmse: 1.8810\n",
      "Epoch 785/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 4.0404 - rmse: 1.9314 - val_loss: 3.5538 - val_rmse: 1.6073\n",
      "Epoch 786/1000\n",
      "5639/5639 [==============================] - 3s 560us/sample - loss: 3.9278 - rmse: 1.9094 - val_loss: 3.5209 - val_rmse: 1.5997\n",
      "Epoch 787/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.9526 - rmse: 1.9171 - val_loss: 4.0966 - val_rmse: 1.7704\n",
      "Epoch 788/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9855 - rmse: 1.9219 - val_loss: 3.5944 - val_rmse: 1.6174\n",
      "Epoch 789/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.9457 - rmse: 1.9122 - val_loss: 4.0430 - val_rmse: 1.7497\n",
      "Epoch 790/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 3.9629 - rmse: 1.9168 - val_loss: 3.5330 - val_rmse: 1.5995\n",
      "Epoch 791/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 3.8525 - rmse: 1.8921 - val_loss: 3.5396 - val_rmse: 1.6037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.9360 - rmse: 1.9110 - val_loss: 4.0711 - val_rmse: 1.7556\n",
      "Epoch 793/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.9078 - rmse: 1.9021 - val_loss: 3.6266 - val_rmse: 1.6293\n",
      "Epoch 794/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9414 - rmse: 1.9085 - val_loss: 3.5735 - val_rmse: 1.6142\n",
      "Epoch 795/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.8915 - rmse: 1.8980 - val_loss: 4.0141 - val_rmse: 1.7416\n",
      "Epoch 796/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.9442 - rmse: 1.9084 - val_loss: 3.6681 - val_rmse: 1.6409\n",
      "Epoch 797/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.8737 - rmse: 1.8977 - val_loss: 3.8459 - val_rmse: 1.6836\n",
      "Epoch 798/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9299 - rmse: 1.9097 - val_loss: 3.5914 - val_rmse: 1.6173\n",
      "Epoch 799/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9502 - rmse: 1.9106 - val_loss: 3.8890 - val_rmse: 1.6988\n",
      "Epoch 800/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 3.9037 - rmse: 1.9014 - val_loss: 4.0037 - val_rmse: 1.7364\n",
      "Epoch 801/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.9053 - rmse: 1.9007 - val_loss: 3.9896 - val_rmse: 1.7346\n",
      "Epoch 802/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9286 - rmse: 1.9045 - val_loss: 3.5908 - val_rmse: 1.6151\n",
      "Epoch 803/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.9216 - rmse: 1.9052 - val_loss: 5.3076 - val_rmse: 2.0800\n",
      "Epoch 804/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.9907 - rmse: 1.9187 - val_loss: 3.7702 - val_rmse: 1.6709\n",
      "Epoch 805/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.8588 - rmse: 1.8921 - val_loss: 4.1837 - val_rmse: 1.7856\n",
      "Epoch 806/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8973 - rmse: 1.8975 - val_loss: 4.7219 - val_rmse: 1.9265\n",
      "Epoch 807/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.9027 - rmse: 1.8991 - val_loss: 3.5386 - val_rmse: 1.6022\n",
      "Epoch 808/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8730 - rmse: 1.8942 - val_loss: 3.8905 - val_rmse: 1.7067\n",
      "Epoch 809/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.8767 - rmse: 1.8940 - val_loss: 3.5737 - val_rmse: 1.6091\n",
      "Epoch 810/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.8159 - rmse: 1.8812 - val_loss: 3.5597 - val_rmse: 1.6072\n",
      "Epoch 811/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.8631 - rmse: 1.8915 - val_loss: 4.1451 - val_rmse: 1.7763\n",
      "Epoch 812/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.8660 - rmse: 1.8912 - val_loss: 4.1114 - val_rmse: 1.7643\n",
      "Epoch 813/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.8493 - rmse: 1.8861 - val_loss: 3.7076 - val_rmse: 1.6512\n",
      "Epoch 814/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8500 - rmse: 1.8886 - val_loss: 4.1853 - val_rmse: 1.7865\n",
      "Epoch 815/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8625 - rmse: 1.8907 - val_loss: 3.5627 - val_rmse: 1.6069\n",
      "Epoch 816/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7992 - rmse: 1.8762 - val_loss: 3.9272 - val_rmse: 1.7087\n",
      "Epoch 817/1000\n",
      "5639/5639 [==============================] - 3s 543us/sample - loss: 3.7966 - rmse: 1.8729 - val_loss: 3.7851 - val_rmse: 1.6723\n",
      "Epoch 818/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.8052 - rmse: 1.8778 - val_loss: 3.9036 - val_rmse: 1.7084\n",
      "Epoch 819/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7905 - rmse: 1.8743 - val_loss: 3.7383 - val_rmse: 1.6574\n",
      "Epoch 820/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 3.8167 - rmse: 1.8792 - val_loss: 4.4567 - val_rmse: 1.8524\n",
      "Epoch 821/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.8691 - rmse: 1.8906 - val_loss: 4.1485 - val_rmse: 1.7724\n",
      "Epoch 822/1000\n",
      "5639/5639 [==============================] - 3s 541us/sample - loss: 3.9036 - rmse: 1.8958 - val_loss: 3.7162 - val_rmse: 1.6504\n",
      "Epoch 823/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.7797 - rmse: 1.8676 - val_loss: 4.2348 - val_rmse: 1.8022\n",
      "Epoch 824/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 3.7800 - rmse: 1.8687 - val_loss: 3.5389 - val_rmse: 1.5995\n",
      "Epoch 825/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.8047 - rmse: 1.8766 - val_loss: 3.6223 - val_rmse: 1.6226\n",
      "Epoch 826/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7564 - rmse: 1.8664 - val_loss: 3.7273 - val_rmse: 1.6560\n",
      "Epoch 827/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8070 - rmse: 1.8736 - val_loss: 4.6400 - val_rmse: 1.9081\n",
      "Epoch 828/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.7749 - rmse: 1.8667 - val_loss: 3.6470 - val_rmse: 1.6319\n",
      "Epoch 829/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7932 - rmse: 1.8704 - val_loss: 4.0368 - val_rmse: 1.7479\n",
      "Epoch 830/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.7584 - rmse: 1.8639 - val_loss: 5.3298 - val_rmse: 2.0795\n",
      "Epoch 831/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.8335 - rmse: 1.8780 - val_loss: 4.2264 - val_rmse: 1.7994\n",
      "Epoch 832/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 3.7877 - rmse: 1.8690 - val_loss: 3.5242 - val_rmse: 1.5990\n",
      "Epoch 833/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.7538 - rmse: 1.8636 - val_loss: 3.9492 - val_rmse: 1.7193\n",
      "Epoch 834/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7899 - rmse: 1.8669 - val_loss: 3.8046 - val_rmse: 1.6839\n",
      "Epoch 835/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.7124 - rmse: 1.8523 - val_loss: 4.5581 - val_rmse: 1.8865\n",
      "Epoch 836/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7262 - rmse: 1.8547 - val_loss: 3.8053 - val_rmse: 1.6762\n",
      "Epoch 837/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7089 - rmse: 1.8506 - val_loss: 3.5205 - val_rmse: 1.5996\n",
      "Epoch 838/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7399 - rmse: 1.8563 - val_loss: 3.7775 - val_rmse: 1.6720\n",
      "Epoch 839/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6895 - rmse: 1.8460 - val_loss: 3.5849 - val_rmse: 1.6139\n",
      "Epoch 840/1000\n",
      "5639/5639 [==============================] - 3s 535us/sample - loss: 3.6841 - rmse: 1.8438 - val_loss: 3.6242 - val_rmse: 1.6276\n",
      "Epoch 841/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.7246 - rmse: 1.8547 - val_loss: 3.5677 - val_rmse: 1.6095\n",
      "Epoch 842/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.6662 - rmse: 1.8381 - val_loss: 3.5496 - val_rmse: 1.6020\n",
      "Epoch 843/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.7197 - rmse: 1.8556 - val_loss: 3.9475 - val_rmse: 1.7179\n",
      "Epoch 844/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6323 - rmse: 1.8318 - val_loss: 3.8497 - val_rmse: 1.6894\n",
      "Epoch 845/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.7130 - rmse: 1.8514 - val_loss: 3.5947 - val_rmse: 1.6227\n",
      "Epoch 846/1000\n",
      "5639/5639 [==============================] - 3s 552us/sample - loss: 3.6754 - rmse: 1.8414 - val_loss: 3.5179 - val_rmse: 1.5939\n",
      "Epoch 847/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 3.6732 - rmse: 1.8400 - val_loss: 4.1866 - val_rmse: 1.7865\n",
      "Epoch 848/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6927 - rmse: 1.8457 - val_loss: 4.1955 - val_rmse: 1.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6804 - rmse: 1.8425 - val_loss: 3.6184 - val_rmse: 1.6230\n",
      "Epoch 850/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.6361 - rmse: 1.8307 - val_loss: 4.2361 - val_rmse: 1.7981\n",
      "Epoch 851/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.7177 - rmse: 1.8501 - val_loss: 3.6786 - val_rmse: 1.6357\n",
      "Epoch 852/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6561 - rmse: 1.8390 - val_loss: 3.5397 - val_rmse: 1.5977\n",
      "Epoch 853/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6424 - rmse: 1.8349 - val_loss: 3.5384 - val_rmse: 1.6020\n",
      "Epoch 854/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.6306 - rmse: 1.8306 - val_loss: 3.8262 - val_rmse: 1.6832\n",
      "Epoch 855/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6455 - rmse: 1.8347 - val_loss: 3.8853 - val_rmse: 1.7001\n",
      "Epoch 856/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.6289 - rmse: 1.8292 - val_loss: 5.4646 - val_rmse: 2.1119\n",
      "Epoch 857/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.7193 - rmse: 1.8469 - val_loss: 3.5233 - val_rmse: 1.5961\n",
      "Epoch 858/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 3.5827 - rmse: 1.8179 - val_loss: 3.8800 - val_rmse: 1.6994\n",
      "Epoch 859/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6127 - rmse: 1.8256 - val_loss: 3.7794 - val_rmse: 1.6682\n",
      "Epoch 860/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 3.6430 - rmse: 1.8309 - val_loss: 3.6177 - val_rmse: 1.6197\n",
      "Epoch 861/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.6424 - rmse: 1.8298 - val_loss: 3.5899 - val_rmse: 1.6158\n",
      "Epoch 862/1000\n",
      "5639/5639 [==============================] - 3s 536us/sample - loss: 3.6047 - rmse: 1.8214 - val_loss: 4.4418 - val_rmse: 1.8549\n",
      "Epoch 863/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.6230 - rmse: 1.8268 - val_loss: 4.6258 - val_rmse: 1.9076\n",
      "Epoch 864/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.6578 - rmse: 1.8357 - val_loss: 4.4705 - val_rmse: 1.8602\n",
      "Epoch 865/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6324 - rmse: 1.8276 - val_loss: 3.5369 - val_rmse: 1.5981\n",
      "Epoch 866/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6118 - rmse: 1.8227 - val_loss: 3.6385 - val_rmse: 1.6295\n",
      "Epoch 867/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.5882 - rmse: 1.8193 - val_loss: 4.4163 - val_rmse: 1.8455\n",
      "Epoch 868/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6338 - rmse: 1.8275 - val_loss: 4.1126 - val_rmse: 1.7650\n",
      "Epoch 869/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6437 - rmse: 1.8321 - val_loss: 3.5220 - val_rmse: 1.5949\n",
      "Epoch 870/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.6293 - rmse: 1.8288 - val_loss: 3.5662 - val_rmse: 1.6070\n",
      "Epoch 871/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.6424 - rmse: 1.8316 - val_loss: 3.5693 - val_rmse: 1.6097\n",
      "Epoch 872/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.5352 - rmse: 1.8040 - val_loss: 3.6209 - val_rmse: 1.6239\n",
      "Epoch 873/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.5048 - rmse: 1.8003 - val_loss: 3.8897 - val_rmse: 1.7033\n",
      "Epoch 874/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5478 - rmse: 1.8096 - val_loss: 3.6869 - val_rmse: 1.6416\n",
      "Epoch 875/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.5771 - rmse: 1.8153 - val_loss: 3.8615 - val_rmse: 1.6934\n",
      "Epoch 876/1000\n",
      "5639/5639 [==============================] - 3s 559us/sample - loss: 3.5411 - rmse: 1.8056 - val_loss: 3.5074 - val_rmse: 1.5910\n",
      "Epoch 877/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.5461 - rmse: 1.8071 - val_loss: 3.6495 - val_rmse: 1.6314\n",
      "Epoch 878/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.5481 - rmse: 1.8052 - val_loss: 3.9212 - val_rmse: 1.7140\n",
      "Epoch 879/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5734 - rmse: 1.8106 - val_loss: 3.5989 - val_rmse: 1.6175\n",
      "Epoch 880/1000\n",
      "5639/5639 [==============================] - 3s 566us/sample - loss: 3.5099 - rmse: 1.7996 - val_loss: 3.4931 - val_rmse: 1.5851\n",
      "Epoch 881/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.4981 - rmse: 1.7939 - val_loss: 3.6570 - val_rmse: 1.6317\n",
      "Epoch 882/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.4920 - rmse: 1.7931 - val_loss: 3.7941 - val_rmse: 1.6713\n",
      "Epoch 883/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.5048 - rmse: 1.7994 - val_loss: 5.1871 - val_rmse: 2.0471\n",
      "Epoch 884/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.6200 - rmse: 1.8195 - val_loss: 3.6252 - val_rmse: 1.6344\n",
      "Epoch 885/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.5150 - rmse: 1.7960 - val_loss: 3.5914 - val_rmse: 1.6145\n",
      "Epoch 886/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5650 - rmse: 1.8078 - val_loss: 3.6643 - val_rmse: 1.6373\n",
      "Epoch 887/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.5814 - rmse: 1.8116 - val_loss: 4.9989 - val_rmse: 1.9943\n",
      "Epoch 888/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5736 - rmse: 1.8088 - val_loss: 4.5319 - val_rmse: 1.8801\n",
      "Epoch 889/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5773 - rmse: 1.8107 - val_loss: 3.4820 - val_rmse: 1.5895\n",
      "Epoch 890/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5173 - rmse: 1.7989 - val_loss: 3.6439 - val_rmse: 1.6400\n",
      "Epoch 891/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.5286 - rmse: 1.7986 - val_loss: 3.5112 - val_rmse: 1.5935\n",
      "Epoch 892/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.5184 - rmse: 1.7965 - val_loss: 3.9543 - val_rmse: 1.7247\n",
      "Epoch 893/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.5279 - rmse: 1.7984 - val_loss: 3.6439 - val_rmse: 1.6280\n",
      "Epoch 894/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.4866 - rmse: 1.7892 - val_loss: 3.5460 - val_rmse: 1.6022\n",
      "Epoch 895/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.5309 - rmse: 1.7989 - val_loss: 3.6085 - val_rmse: 1.6169\n",
      "Epoch 896/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.5214 - rmse: 1.7968 - val_loss: 3.5818 - val_rmse: 1.6103\n",
      "Epoch 897/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4684 - rmse: 1.7864 - val_loss: 3.6580 - val_rmse: 1.6318\n",
      "Epoch 898/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.4890 - rmse: 1.7910 - val_loss: 3.6240 - val_rmse: 1.6276\n",
      "Epoch 899/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.4608 - rmse: 1.7807 - val_loss: 3.5119 - val_rmse: 1.5939\n",
      "Epoch 900/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 3.4296 - rmse: 1.7771 - val_loss: 3.7594 - val_rmse: 1.6647\n",
      "Epoch 901/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.4527 - rmse: 1.7817 - val_loss: 4.5722 - val_rmse: 1.8910\n",
      "Epoch 902/1000\n",
      "5639/5639 [==============================] - 3s 539us/sample - loss: 3.4742 - rmse: 1.7850 - val_loss: 3.6653 - val_rmse: 1.6342\n",
      "Epoch 903/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 3.4612 - rmse: 1.7803 - val_loss: 3.8315 - val_rmse: 1.6868\n",
      "Epoch 904/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3970 - rmse: 1.7672 - val_loss: 4.1681 - val_rmse: 1.7819\n",
      "Epoch 905/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4849 - rmse: 1.7849 - val_loss: 4.0048 - val_rmse: 1.7290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.4812 - rmse: 1.7880 - val_loss: 4.4837 - val_rmse: 1.8682\n",
      "Epoch 907/1000\n",
      "5639/5639 [==============================] - 3s 524us/sample - loss: 3.4267 - rmse: 1.7728 - val_loss: 3.8388 - val_rmse: 1.6844\n",
      "Epoch 908/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4545 - rmse: 1.7814 - val_loss: 3.6709 - val_rmse: 1.6366\n",
      "Epoch 909/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4388 - rmse: 1.7759 - val_loss: 3.5144 - val_rmse: 1.5945\n",
      "Epoch 910/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4363 - rmse: 1.7775 - val_loss: 5.7384 - val_rmse: 2.1810\n",
      "Epoch 911/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.5084 - rmse: 1.7913 - val_loss: 3.9488 - val_rmse: 1.7191\n",
      "Epoch 912/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.4277 - rmse: 1.7728 - val_loss: 3.8723 - val_rmse: 1.7021\n",
      "Epoch 913/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.3951 - rmse: 1.7631 - val_loss: 3.6359 - val_rmse: 1.6316\n",
      "Epoch 914/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.3915 - rmse: 1.7660 - val_loss: 4.4139 - val_rmse: 1.8506\n",
      "Epoch 915/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.4502 - rmse: 1.7773 - val_loss: 3.7812 - val_rmse: 1.6731\n",
      "Epoch 916/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.3886 - rmse: 1.7632 - val_loss: 4.2969 - val_rmse: 1.8132\n",
      "Epoch 917/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 3.4401 - rmse: 1.7758 - val_loss: 3.8514 - val_rmse: 1.7015\n",
      "Epoch 918/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.4370 - rmse: 1.7766 - val_loss: 3.9607 - val_rmse: 1.7187\n",
      "Epoch 919/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.4190 - rmse: 1.7674 - val_loss: 3.5833 - val_rmse: 1.6108\n",
      "Epoch 920/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3634 - rmse: 1.7545 - val_loss: 3.8445 - val_rmse: 1.6868\n",
      "Epoch 921/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.3932 - rmse: 1.7640 - val_loss: 3.9518 - val_rmse: 1.7215\n",
      "Epoch 922/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.3837 - rmse: 1.7599 - val_loss: 3.4910 - val_rmse: 1.5877\n",
      "Epoch 923/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.3585 - rmse: 1.7548 - val_loss: 3.5435 - val_rmse: 1.5995\n",
      "Epoch 924/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.3560 - rmse: 1.7539 - val_loss: 3.8019 - val_rmse: 1.6757\n",
      "Epoch 925/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.3448 - rmse: 1.7501 - val_loss: 3.5134 - val_rmse: 1.5898\n",
      "Epoch 926/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3884 - rmse: 1.7626 - val_loss: 3.9772 - val_rmse: 1.7310\n",
      "Epoch 927/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3548 - rmse: 1.7530 - val_loss: 3.9530 - val_rmse: 1.7187\n",
      "Epoch 928/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.3636 - rmse: 1.7553 - val_loss: 3.9924 - val_rmse: 1.7323\n",
      "Epoch 929/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.3667 - rmse: 1.7531 - val_loss: 3.6065 - val_rmse: 1.6180\n",
      "Epoch 930/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.3254 - rmse: 1.7462 - val_loss: 3.7943 - val_rmse: 1.6772\n",
      "Epoch 931/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3676 - rmse: 1.7566 - val_loss: 3.5772 - val_rmse: 1.6085\n",
      "Epoch 932/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.3243 - rmse: 1.7469 - val_loss: 4.6950 - val_rmse: 1.9205\n",
      "Epoch 933/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.3728 - rmse: 1.7562 - val_loss: 3.7056 - val_rmse: 1.6566\n",
      "Epoch 934/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3581 - rmse: 1.7521 - val_loss: 3.8536 - val_rmse: 1.6916\n",
      "Epoch 935/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.3209 - rmse: 1.7422 - val_loss: 3.9538 - val_rmse: 1.7246\n",
      "Epoch 936/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.3040 - rmse: 1.7405 - val_loss: 4.0680 - val_rmse: 1.7549\n",
      "Epoch 937/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3070 - rmse: 1.7411 - val_loss: 4.0617 - val_rmse: 1.7562\n",
      "Epoch 938/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3461 - rmse: 1.7477 - val_loss: 3.5401 - val_rmse: 1.6043\n",
      "Epoch 939/1000\n",
      "5639/5639 [==============================] - 3s 556us/sample - loss: 3.3677 - rmse: 1.7558 - val_loss: 3.4656 - val_rmse: 1.5802\n",
      "Epoch 940/1000\n",
      "5639/5639 [==============================] - 3s 553us/sample - loss: 3.3078 - rmse: 1.7410 - val_loss: 3.8622 - val_rmse: 1.6961\n",
      "Epoch 941/1000\n",
      "5639/5639 [==============================] - 3s 545us/sample - loss: 3.2976 - rmse: 1.7376 - val_loss: 3.7108 - val_rmse: 1.6498\n",
      "Epoch 942/1000\n",
      "5639/5639 [==============================] - 3s 533us/sample - loss: 3.3518 - rmse: 1.7504 - val_loss: 3.8545 - val_rmse: 1.6959\n",
      "Epoch 943/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2925 - rmse: 1.7349 - val_loss: 3.4947 - val_rmse: 1.5824\n",
      "Epoch 944/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.2954 - rmse: 1.7368 - val_loss: 3.4992 - val_rmse: 1.5855\n",
      "Epoch 945/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3063 - rmse: 1.7400 - val_loss: 3.6876 - val_rmse: 1.6349\n",
      "Epoch 946/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.2970 - rmse: 1.7371 - val_loss: 3.5312 - val_rmse: 1.5956\n",
      "Epoch 947/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.2887 - rmse: 1.7362 - val_loss: 3.7494 - val_rmse: 1.6647\n",
      "Epoch 948/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3243 - rmse: 1.7406 - val_loss: 4.0772 - val_rmse: 1.7542\n",
      "Epoch 949/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.2887 - rmse: 1.7321 - val_loss: 4.4541 - val_rmse: 1.8604\n",
      "Epoch 950/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.3257 - rmse: 1.7418 - val_loss: 3.9854 - val_rmse: 1.7261\n",
      "Epoch 951/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2913 - rmse: 1.7325 - val_loss: 4.0987 - val_rmse: 1.7611\n",
      "Epoch 952/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.2784 - rmse: 1.7300 - val_loss: 3.6270 - val_rmse: 1.6245\n",
      "Epoch 953/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.3141 - rmse: 1.7407 - val_loss: 3.5326 - val_rmse: 1.5944\n",
      "Epoch 954/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.2717 - rmse: 1.7312 - val_loss: 4.0966 - val_rmse: 1.7592\n",
      "Epoch 955/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2296 - rmse: 1.7177 - val_loss: 3.9350 - val_rmse: 1.7091\n",
      "Epoch 956/1000\n",
      "5639/5639 [==============================] - 3s 558us/sample - loss: 3.2767 - rmse: 1.7303 - val_loss: 3.4454 - val_rmse: 1.5694\n",
      "Epoch 957/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.3116 - rmse: 1.7385 - val_loss: 3.6541 - val_rmse: 1.6302\n",
      "Epoch 958/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.2449 - rmse: 1.7229 - val_loss: 4.3670 - val_rmse: 1.8291\n",
      "Epoch 959/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.3031 - rmse: 1.7343 - val_loss: 3.6461 - val_rmse: 1.6275\n",
      "Epoch 960/1000\n",
      "5639/5639 [==============================] - 3s 555us/sample - loss: 3.2108 - rmse: 1.7152 - val_loss: 3.4513 - val_rmse: 1.5661\n",
      "Epoch 961/1000\n",
      "5639/5639 [==============================] - 3s 538us/sample - loss: 3.2503 - rmse: 1.7253 - val_loss: 4.2837 - val_rmse: 1.8116\n",
      "Epoch 962/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.2839 - rmse: 1.7285 - val_loss: 3.4486 - val_rmse: 1.5670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2259 - rmse: 1.7183 - val_loss: 3.5399 - val_rmse: 1.5957\n",
      "Epoch 964/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.2585 - rmse: 1.7236 - val_loss: 3.6889 - val_rmse: 1.6443\n",
      "Epoch 965/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.1988 - rmse: 1.7120 - val_loss: 3.6876 - val_rmse: 1.6384\n",
      "Epoch 966/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.1948 - rmse: 1.7087 - val_loss: 3.4811 - val_rmse: 1.5791\n",
      "Epoch 967/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.2208 - rmse: 1.7203 - val_loss: 3.4932 - val_rmse: 1.5809\n",
      "Epoch 968/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.2037 - rmse: 1.7104 - val_loss: 4.0714 - val_rmse: 1.7529\n",
      "Epoch 969/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.2237 - rmse: 1.7176 - val_loss: 3.6906 - val_rmse: 1.6392\n",
      "Epoch 970/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.2173 - rmse: 1.7102 - val_loss: 3.4493 - val_rmse: 1.5689\n",
      "Epoch 971/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.2296 - rmse: 1.7169 - val_loss: 3.6692 - val_rmse: 1.6282\n",
      "Epoch 972/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.1678 - rmse: 1.7000 - val_loss: 3.6399 - val_rmse: 1.6227\n",
      "Epoch 973/1000\n",
      "5639/5639 [==============================] - 3s 528us/sample - loss: 3.1988 - rmse: 1.7066 - val_loss: 4.6657 - val_rmse: 1.9062\n",
      "Epoch 974/1000\n",
      "5639/5639 [==============================] - 3s 525us/sample - loss: 3.2225 - rmse: 1.7175 - val_loss: 3.5128 - val_rmse: 1.5861\n",
      "Epoch 975/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.1830 - rmse: 1.7045 - val_loss: 3.4723 - val_rmse: 1.5760\n",
      "Epoch 976/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.1767 - rmse: 1.7029 - val_loss: 3.4563 - val_rmse: 1.5683\n",
      "Epoch 977/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.1829 - rmse: 1.7051 - val_loss: 3.4651 - val_rmse: 1.5715\n",
      "Epoch 978/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1617 - rmse: 1.7000 - val_loss: 3.5140 - val_rmse: 1.5952\n",
      "Epoch 979/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2351 - rmse: 1.7134 - val_loss: 3.5070 - val_rmse: 1.5854\n",
      "Epoch 980/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.2267 - rmse: 1.7118 - val_loss: 4.3266 - val_rmse: 1.8266\n",
      "Epoch 981/1000\n",
      "5639/5639 [==============================] - 3s 534us/sample - loss: 3.2159 - rmse: 1.7101 - val_loss: 3.4404 - val_rmse: 1.5692\n",
      "Epoch 982/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1641 - rmse: 1.7006 - val_loss: 4.7437 - val_rmse: 1.9394\n",
      "Epoch 983/1000\n",
      "5639/5639 [==============================] - 3s 537us/sample - loss: 3.2663 - rmse: 1.7220 - val_loss: 3.7941 - val_rmse: 1.6732\n",
      "Epoch 984/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.1639 - rmse: 1.6984 - val_loss: 3.9780 - val_rmse: 1.7320\n",
      "Epoch 985/1000\n",
      "5639/5639 [==============================] - 3s 527us/sample - loss: 3.1387 - rmse: 1.6929 - val_loss: 3.5871 - val_rmse: 1.6099\n",
      "Epoch 986/1000\n",
      "5639/5639 [==============================] - 3s 557us/sample - loss: 3.1970 - rmse: 1.7075 - val_loss: 3.4183 - val_rmse: 1.5637\n",
      "Epoch 987/1000\n",
      "5639/5639 [==============================] - 3s 532us/sample - loss: 3.1608 - rmse: 1.6997 - val_loss: 3.4579 - val_rmse: 1.5699\n",
      "Epoch 988/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.2009 - rmse: 1.7083 - val_loss: 3.4787 - val_rmse: 1.5781\n",
      "Epoch 989/1000\n",
      "5639/5639 [==============================] - 3s 526us/sample - loss: 3.1438 - rmse: 1.6947 - val_loss: 3.7555 - val_rmse: 1.6620\n",
      "Epoch 990/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.1731 - rmse: 1.7000 - val_loss: 3.5224 - val_rmse: 1.5901\n",
      "Epoch 991/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1328 - rmse: 1.6905 - val_loss: 3.5639 - val_rmse: 1.6104\n",
      "Epoch 992/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1584 - rmse: 1.6961 - val_loss: 4.0508 - val_rmse: 1.7517\n",
      "Epoch 993/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1671 - rmse: 1.6992 - val_loss: 4.5111 - val_rmse: 1.8762\n",
      "Epoch 994/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.1674 - rmse: 1.6975 - val_loss: 3.7542 - val_rmse: 1.6596\n",
      "Epoch 995/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.1091 - rmse: 1.6823 - val_loss: 3.8014 - val_rmse: 1.6788\n",
      "Epoch 996/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1882 - rmse: 1.7024 - val_loss: 3.9666 - val_rmse: 1.7178\n",
      "Epoch 997/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.1428 - rmse: 1.6957 - val_loss: 3.9641 - val_rmse: 1.7238\n",
      "Epoch 998/1000\n",
      "5639/5639 [==============================] - 3s 529us/sample - loss: 3.1367 - rmse: 1.6905 - val_loss: 3.4508 - val_rmse: 1.5698\n",
      "Epoch 999/1000\n",
      "5639/5639 [==============================] - 3s 530us/sample - loss: 3.0804 - rmse: 1.6785 - val_loss: 3.8164 - val_rmse: 1.6832\n",
      "Epoch 1000/1000\n",
      "5639/5639 [==============================] - 3s 531us/sample - loss: 3.1891 - rmse: 1.7027 - val_loss: 3.5277 - val_rmse: 1.6009\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = 1000,\n",
    "                    batch_size = 256,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = callbacks\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(history.history['rmse'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    "plt.title('Model Training Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211\n"
     ]
    }
   ],
   "source": [
    "sess = get_session()\n",
    "clear_session()\n",
    "sess.close()\n",
    "sess = get_session()\n",
    "try:\n",
    "    del model # this is from global space - change this as you need\n",
    "except:\n",
    "    print(\"Model clear Failed\")\n",
    "print(gc.collect())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
